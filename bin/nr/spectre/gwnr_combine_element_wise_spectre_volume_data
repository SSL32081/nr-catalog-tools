#!/usr/bin/env python
#
# Copyright (C) 2020 Prayush Kumar
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

import time
import h5py
import os
import sys
import numpy as np
import pandas as pd
import logging
import argparse

__author__ = "Prayush Kumar <prayush.kumar@gmail.com>"
PROGRAM_NAME = os.path.abspath(sys.argv[0])

logging.getLogger().setLevel(logging.INFO)

__itime__ = time.time()


def add_dataframe_to_hdf5_group(hdf_group, df):
    """This function takes in a pointer to an open HDF5 file group, within
    which data is to be stored. It also takes in a pandas.DataFrame of tensor
    components. It stores the columns in latter as datasets in the former.
    """
    for t in df.columns:
        if t in hdf_group:
            logging.info("Skipping tensor {}".format(t))
            continue
        hdf_group.create_dataset(t, data=df[t].to_numpy())
        logging.info("Added tensor {}".format(t))


def combine_element_wise_spectre_data(hdf_group,
                                      include='all', exclude=[],
                                      combined_tensors={},
                                      verbose=True):
    """This function takes in a pointer to an open HDF5 file group, within
    which is data stored in spectre's ExtentsAndTensorVolumeData format, i.e.
    in subgroups for each element, there are all tensor components stored
    for the same. The optional inputs `include` and `exclude` are lists of
    tensors to collate (or not).
    """
    # Use the first element to get a list of tensors and elements
    elements = list(hdf_group.keys())
    first_elem = elements[0]
    all_tensors = list(hdf_group[first_elem].keys())
    # Include only those tensors that the user specifies in include
    if type(include) is list:
        all_tensors = list(set(all_tensors).intersection(set(include)))
        if len(all_tensors) == 0:
            raise IOError("Did you want to include any tensors..?")
    elif include == 'all':
        pass
    else:
        raise IOError(
            "Either provide a list of tensor components as `include` OR just 'all'")
    # Exclude tensors the user requests for
    assert type(exclude) is list, "Provide an empty of filled list as exclude"
    all_tensors = list(set(all_tensors).difference(set(exclude)))
    # Collate and populate tensors
    for t in all_tensors:
        if verbose:
            logging.info("... combining data for {}".format(t))
        if t not in combined_tensors:
            combined_tensors[t] = []
        for sd in elements:
            combined_tensors[t] = np.append(
                combined_tensors[t], hdf_group[sd][t][()])
    return combined_tensors


precision_decimals = 10


if __name__ == "__main__":
    help = """Takes a volume-data HDF5 file that contains
    SpacetimeMetric, Pi, and Phi, H, D4H, stored seperately
    for each element, and collates it for all elements to
    conform with the current spectre-volume-data format.
    """
    parser = argparse.ArgumentParser(description=help)
    parser.add_argument('--input-volume-data-file', required=True,
                        help="""Name of HDF5 file""")
    parser.add_argument('--spectre-points-file', required=True,
                        help="""Name of HDF5 file""")
    parser.add_argument('--insert-at-time', required=False, type=float,
                        default=0.0,
                        help="""Value of time at which to add data""")
    parser.add_argument('--output-file', required=True,
                        help="""Name of HDF5 file""")
    args = parser.parse_args()

    base = 'element_data.vol'

    logging.info("Making a copy of {0} to {1}".format(
        args.spectre_points_file, args.output_file))
    os.system(
        "cp -r {0} {1}".format(args.spectre_points_file, args.output_file))

    ct = {}
    with h5py.File(args.input_volume_data_file, 'r') as f:
        base = 'element_data.vol'
        observation_id = list(f[base].keys())[0]  # use first observation
        h = f[base][observation_id]
        for t in list(h[list(h.keys())[0]].keys()):
            if 'Gauge' not in t and \
                'Spacetime' not in t and \
                'Pi' not in t and \
                'Phi' not in t and \
                    'Coordinates' not in t:
                continue
            ct = combine_element_wise_spectre_data(h, include=[t],
                                                   combined_tensors=ct)
    df_gl_id = pd.DataFrame.from_dict(ct)
    df_gl_id['InertialCoordinates'] =\
        [(_x, _y, _z) for (_x, _y, _z) in zip(
            np.around(df_gl_id['InertialCoordinates_x'].to_numpy(),
                      decimals=precision_decimals),
            np.around(df_gl_id['InertialCoordinates_y'].to_numpy(),
                      decimals=precision_decimals),
            np.around(df_gl_id['InertialCoordinates_z'].to_numpy(),
                      decimals=precision_decimals))]
    dest_ct = {}
    with h5py.File(args.spectre_points_file, 'r') as f:
        base = 'element_data.vol'
        observation_id = list(f[base].keys())[0]  # use first observation
        h = f[base][observation_id]
        logging.info(dict(h).keys())
        for kk in h:
            dest_ct[kk] = h[kk][()]
    # Remove columns that we do not need for merging with GL's ID
    dest_ct.pop('connectivity')
    dest_ct.pop('grid_names')
    dest_ct.pop('total_extents')
    df_dest_id = pd.DataFrame.from_dict(dest_ct)
    df_dest_id['InertialCoordinates'] =\
        [(_x, _y, _z) for (_x, _y, _z) in zip(
            np.around(df_dest_id['InertialCoordinates_x'].to_numpy(),
                      decimals=precision_decimals),
            np.around(df_dest_id['InertialCoordinates_y'].to_numpy(),
                      decimals=precision_decimals),
            np.around(df_dest_id['InertialCoordinates_z'].to_numpy(),
                      decimals=precision_decimals))]
    df_dest_id_for_merge = df_dest_id  # alias only
    df_dest_id_for_merge.drop(
        labels=['InertialCoordinates_x'], axis='columns', inplace=True)
    df_dest_id_for_merge.drop(
        labels=['InertialCoordinates_y'], axis='columns', inplace=True)
    df_dest_id_for_merge.drop(
        labels=['InertialCoordinates_z'], axis='columns', inplace=True)

    df_joined_id = df_dest_id.merge(df_gl_id.drop_duplicates(['InertialCoordinates']),
                                    how='left',
                                    on='InertialCoordinates')
    copy_df_joined_id = df_joined_id.copy()
    copy_df_joined_id.pop('InertialCoordinates')
    with h5py.File(args.output_file, "a") as f:
        base = 'element_data.vol'
        time_found = False
        for observation_id in f[base]:
            if f[base][observation_id].attrs['observation_value'] == args.insert_at_time:
                time_found = True
                break
        if not time_found:
            raise IOError("Data insertion time {} not present in points file".format(
                args.insert_at_time))
        h = f[base][observation_id]
        add_dataframe_to_hdf5_group(h, copy_df_joined_id)
        logging.info("Written data to disk.")

    logging.info("All done in {} secs.".format(time.time() - __itime__))
