{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and run Bayesian inference on a batch of GW events using `pycbc_inference`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "run_dir = '/home/prayush/research/test_pycbc_gw150914'\n",
    "try: os.makedirs(run_dir)\n",
    "except: pass\n",
    "os.chdir(run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prayush/research/test_pycbc_gw150914\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Generate sampler / inference config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prayush/miniconda3/envs/lalsuite-dev/lib/python3.9/site-packages/pandas/core/common.py:208: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n",
      "usage: /home/prayush/miniconda3/envs/lalsuite-dev/lib/python3.9/site-packages/gwnrtools-2020.10.30-py3.9.egg/EGG-INFO/scripts/gwnrtools_write_pycbc_inference_configs [--options]\n",
      "\n",
      "Get and write configuration files for generating a workflow to perform\n",
      "Bayesian parameter estimation runs on a set of signals with Pycbc inference\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --version             Prints version information.\n",
      "  --verbose             Print logging messages.\n",
      "  --write-data-config WRITE_DATA_CONFIG\n",
      "                        Write data config files and exit.\n",
      "  --write-sampler-config WRITE_SAMPLER_CONFIG\n",
      "                        Write sampler config files and exit.\n",
      "  --write-inference-config WRITE_INFERENCE_CONFIG\n",
      "                        Write inference config files and exit.\n",
      "  --n-cpus N_CPUS\n",
      "  --checkpoint-interval CHECKPOINT_INTERVAL\n",
      "  --n-live N_LIVE\n",
      "  --n-maxmcmc N_MAXMCMC\n",
      "  --dlogz DLOGZ\n",
      "  --n-walkers N_WALKERS\n",
      "  --n-temperatures N_TEMPERATURES\n",
      "  --n-maxsamps-per-walker N_MAXSAMPS_PER_WALKER\n",
      "  --n-eff-samples N_EFF_SAMPLES\n",
      "  --show-available-configs\n",
      "                        Show available options for all configurations.\n",
      "  --output-dir OUTPUT_DIR\n",
      "                        Output directory path.\n"
     ]
    }
   ],
   "source": [
    "!gwnr_write_pycbc_inference_configs -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prayush/miniconda3/envs/lalsuite-dev/lib/python3.9/site-packages/pandas/core/common.py:208: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n",
      "data: ['gw150914-like-gaussian', 'gw150914-like-zeronoise', 'GW150914-v3', 'GW151012-v3', 'GW151226-v2', 'GW170104-v2', 'GW170608-v3', 'GW170729-v1', 'GW170809-v1', 'GW170814-v3', 'GW170817-v3', 'GW170818-v1', 'GW170823-v1']\n",
      "sampler: ['emcee', 'emcee_pt', 'epsie', 'dynesty', 'ultranest', 'multinest', 'cpnest']\n",
      "inference: ['bbh_precessing', 'bbh_alignedspin']\n"
     ]
    }
   ],
   "source": [
    "!gwnr_write_pycbc_inference_configs --show-available-configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prayush/miniconda3/envs/lalsuite-dev/lib/python3.9/site-packages/pandas/core/common.py:208: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n",
      "2021-09-20 19:37:49,110 Writing config file for sampler settings..\n",
      "2021-09-20 19:37:49,111 Writing config file for inference settings..\n",
      "2021-09-20 19:37:49,111 Done\n"
     ]
    }
   ],
   "source": [
    "!gwnr_write_pycbc_inference_configs --verbose\\\n",
    "  --write-sampler-config emcee_pt --write-inference-config bbh_precessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbh_precessing.ini  emcee_pt.ini\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sampler]\r\n",
      "name = emcee_pt\r\n",
      "nprocesses = 10\r\n",
      "nwalkers = 1000\r\n",
      "ntemps = 20\r\n",
      "effective-nsamples = 4000\r\n",
      "max-samples-per-chain = 1000\r\n",
      "checkpoint-interval = 2000\r\n",
      "\r\n",
      "[sampler-burn_in]\r\n",
      "burn-in-test = nacl & max_posterior\r\n",
      "\r\n",
      ";\r\n",
      ";   Sampling transforms\r\n",
      ";\r\n",
      "[sampling_params]\r\n",
      "; parameters on the left will be sampled in\r\n",
      "; parametes on the right\r\n",
      "mass1, mass2 : mchirp, q\r\n",
      "\r\n",
      "[sampling_transforms-mchirp+q]\r\n",
      "; inputs mass1, mass2\r\n",
      "; outputs mchirp, q\r\n",
      "name = mass1_mass2_to_mchirp_q\r\n",
      "[model]\r\n",
      "name = gaussian_noise\r\n",
      "low-frequency-cutoff = 20.0\r\n",
      "\r\n",
      "[variable_params]\r\n",
      "; waveform parameters that will vary in MCMC\r\n",
      "delta_tc =\r\n",
      "mass1 =\r\n",
      "mass2 =\r\n",
      "spin1_a =\r\n",
      "spin1_azimuthal =\r\n",
      "spin1_polar =\r\n",
      "spin2_a =\r\n",
      "spin2_azimuthal =\r\n",
      "spin2_polar =\r\n",
      "distance =\r\n",
      "coa_phase =\r\n",
      "inclination =\r\n",
      "polarization =\r\n",
      "ra =\r\n",
      "dec =\r\n",
      "\r\n",
      "[static_params]\r\n",
      "; waveform parameters that will not change in MCMC\r\n",
      "approximant = IMRPhenomPv2\r\n",
      "f_lower = 20\r\n",
      "f_ref = 20\r\n",
      "; we'll set the tc by using the trigger time in the data\r\n",
      "; section of the config file + delta_tc\r\n",
      "trigger_time = ${data|trigger-time}\r\n",
      "\r\n",
      "[prior-delta_tc]\r\n",
      "; coalescence time prior\r\n",
      "name = uniform\r\n",
      "min-delta_tc = -0.1\r\n",
      "max-delta_tc = 0.1\r\n",
      "\r\n",
      "[waveform_transforms-tc]\r\n",
      "; we need to provide tc to the waveform generator\r\n",
      "name = custom\r\n",
      "inputs = delta_tc\r\n",
      "tc = ${data|trigger-time} + delta_tc\r\n",
      "\r\n",
      ";Mass1 of GW151012 $\\in$ [28.7, 38.1]\r\n",
      ";Mass1 of GW170608 $\\in$ [12.7, 16.5]\r\n",
      ";Mass1 of GW170729 $\\in$ [60.4, 66.4]\r\n",
      ";Mass1 of GW150914 $\\in$ [38.7, 40.3]\r\n",
      ";Mass1 of GW151226 $\\in$ [16.9, 22.5]\r\n",
      ";Mass1 of GW170814 $\\in$ [33.6, 36.2]\r\n",
      ";Mass1 of GW170817 $\\in$ [1.56, 1.58]\r\n",
      ";Mass1 of GW170104 $\\in$ [36.4, 38.1]\r\n",
      ";Mass1 of GW170809 $\\in$ [40.9, 43.3]\r\n",
      ";Mass1 of GW170818 $\\in$ [40.1, 42.9]\r\n",
      ";Mass1 of GW170823 $\\in$ [46.2, 50.7]\r\n",
      "\r\n",
      "[prior-mass1]\r\n",
      "name = uniform\r\n",
      "min-mass1 = 10.\r\n",
      "max-mass1 = 80.\r\n",
      "\r\n",
      ";Mass2 of GW151012 $\\in$ [18.4, 17.7]\r\n",
      ";Mass2 of GW170608 $\\in$ [9.8, 9.0]\r\n",
      ";Mass2 of GW170729 $\\in$ [44.1, 43.1]\r\n",
      ";Mass2 of GW150914 $\\in$ [35.0, 33.6]\r\n",
      ";Mass2 of GW151226 $\\in$ [10.2, 9.9]\r\n",
      ";Mass2 of GW170814 $\\in$ [29.2, 28.0]\r\n",
      ";Mass2 of GW170817 $\\in$ [1.36, 1.36]\r\n",
      ";Mass2 of GW170104 $\\in$ [24.6, 24.9]\r\n",
      ";Mass2 of GW170809 $\\in$ [29.0, 28.9]\r\n",
      ";Mass2 of GW170818 $\\in$ [31.9, 31.0]\r\n",
      ";Mass2 of GW170823 $\\in$ [36.8, 35.7]\r\n",
      "\r\n",
      "[prior-mass2]\r\n",
      "name = uniform\r\n",
      "min-mass2 = 10.\r\n",
      "max-mass2 = 80.\r\n",
      "\r\n",
      "[prior-spin1_a]\r\n",
      "name = uniform\r\n",
      "min-spin1_a = 0.0\r\n",
      "max-spin1_a = 0.99\r\n",
      "\r\n",
      "[prior-spin1_polar+spin1_azimuthal]\r\n",
      "name = uniform_solidangle\r\n",
      "polar-angle = spin1_polar\r\n",
      "azimuthal-angle = spin1_azimuthal\r\n",
      "\r\n",
      "[prior-spin2_a]\r\n",
      "name = uniform\r\n",
      "min-spin2_a = 0.0\r\n",
      "max-spin2_a = 0.99\r\n",
      "\r\n",
      "[prior-spin2_polar+spin2_azimuthal]\r\n",
      "name = uniform_solidangle\r\n",
      "polar-angle = spin2_polar\r\n",
      "azimuthal-angle = spin2_azimuthal\r\n",
      "\r\n",
      "[prior-distance]\r\n",
      "; following gives a uniform volume prior\r\n",
      "name = uniform_radius\r\n",
      "min-distance = 10\r\n",
      "max-distance = 1000\r\n",
      "\r\n",
      "[prior-coa_phase]\r\n",
      "; coalescence phase prior\r\n",
      "name = uniform_angle\r\n",
      "\r\n",
      "[prior-inclination]\r\n",
      "; inclination prior\r\n",
      "name = sin_angle\r\n",
      "\r\n",
      "[prior-ra+dec]\r\n",
      "; sky position prior\r\n",
      "name = uniform_sky\r\n",
      "\r\n",
      "[prior-polarization]\r\n",
      "; polarization prior\r\n",
      "name = uniform_angle\r\n"
     ]
    }
   ],
   "source": [
    "!cat emcee_pt.ini bbh_precessing.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Write workflow config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('config.ini', 'w') as fout:\n",
    "    fout.write('''\\\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";   Executables\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "[executables]\n",
    "inference = ${which:pycbc_inference}\n",
    "plot = ${which:pycbc_inference_plot_posterior}\n",
    "\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";   Workflow\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "[workflow]\n",
    "accounting-group = ligo.dev.o3.cbc.explore.test\n",
    "log-path = log\n",
    "sampler = emcee_pt.ini\n",
    "inference = bbh_precessing.ini\n",
    "events = GW150914 GW170104\n",
    "sample-rate = 2048\n",
    "data-sample-rate = 4096\n",
    "data-duration = 4096\n",
    "psd-estimation = download ; or data-standard\n",
    "\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";   Inference\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "[inference]\n",
    "verbose =\n",
    "seed = 12\n",
    "config-files = inference.ini data.ini sampler.ini\n",
    "output-file = inference.hdf\n",
    "nprocesses = 10\n",
    "force =\n",
    "\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";   Visualize\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "[plot]\n",
    "input-file = inference.hdf\n",
    "plot-scatter =\n",
    "plot-marginal =\n",
    "plot-prior = inference.ini data.ini\n",
    "\n",
    "[plot-mass1mass2]\n",
    "output-file = plots/posteriors.png\n",
    "parameters = 'mass1 mass2'\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      ";   Executables\r\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      "[executables]\r\n",
      "inference = ${which:pycbc_inference}\r\n",
      "plot = ${which:pycbc_inference_plot_posterior}\r\n",
      "\r\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      ";   Workflow\r\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      "[workflow]\r\n",
      "accounting-group = ligo.dev.o3.cbc.explore.test\r\n",
      "log-path = log\r\n",
      "sampler = emcee_pt.ini\r\n",
      "inference = bbh_precessing.ini\r\n",
      "events = GW150914 GW170104\r\n",
      "sample-rate = 2048\r\n",
      "data-sample-rate = 4096\r\n",
      "data-duration = 4096\r\n",
      "psd-estimation = download ; or data-standard\r\n",
      "\r\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      ";   Inference\r\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      "[inference]\r\n",
      "verbose =\r\n",
      "seed = 12\r\n",
      "config-files = inference.ini data.ini sampler.ini\r\n",
      "output-file = inference.hdf\r\n",
      "nprocesses = 10\r\n",
      "force =\r\n",
      "\r\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      ";   Visualize\r\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      "[plot]\r\n",
      "input-file = inference.hdf\r\n",
      "plot-scatter =\r\n",
      "plot-marginal =\r\n",
      "plot-prior = inference.ini data.ini\r\n",
      "\r\n",
      "[plot-mass1mass2]\r\n",
      "output-file = plots/posteriors.png\r\n",
      "parameters = 'mass1 mass2'\r\n"
     ]
    }
   ],
   "source": [
    "!cat config.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: /home/prayush/src/GWNRTools/bin//gwnrtools_create_public_events_inference_workflow [--options]\r\n",
      "\r\n",
      "Setup workflow to perform Bayesian parameter estimation runs on a custom set\r\n",
      "of public gravitational-wave events using open data\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --version             Prints version information.\r\n",
      "  --verbose             Print logging messages.\r\n",
      "  --output-dir OUTPUT_DIR\r\n",
      "                        Output directory path.\r\n",
      "  --force               If the output-dir already exists, overwrite it.\r\n",
      "                        Otherwise, an OSError is raised.\r\n",
      "  --do-not-fetch-data   Don't fetch GWOSC data.\r\n",
      "  --nprocesses NPROCESSES\r\n",
      "                        Number of processes to use. If not given then only a\r\n",
      "                        single core will be used.\r\n",
      "  --use-mpi             Use MPI to parallelize the sampler\r\n",
      "  --seed SEED           Seed to use for the random number generator that\r\n",
      "                        initially distributes the walkers. Default is 0.\r\n",
      "\r\n",
      "Configuration:\r\n",
      "  Options needed for parsing config file(s).\r\n",
      "\r\n",
      "  --config-files CONFIGFILE [CONFIGFILE ...]\r\n",
      "                        List of config files to be used in analysis.\r\n",
      "  --config-overrides [SECTION:OPTION:VALUE [SECTION:OPTION:VALUE ...]]\r\n",
      "                        List of section,option,value combinations to add into\r\n",
      "                        the configuration file. Normally the gps start and end\r\n",
      "                        times might be provided this way, and user specific\r\n",
      "                        locations (ie. output directories). This can also be\r\n",
      "                        provided as SECTION:OPTION or SECTION:OPTION: both of\r\n",
      "                        which indicate that the corresponding value is left\r\n",
      "                        blank.\r\n",
      "  --config-delete [SECTION:OPTION [SECTION:OPTION ...]]\r\n",
      "                        List of section,option combinations to delete from the\r\n",
      "                        configuration file. This can also be provided as\r\n",
      "                        SECTION which deletes the enture section from the\r\n",
      "                        configuration file or SECTION:OPTION which deletes a\r\n",
      "                        specific option from a given section.\r\n",
      "\r\n",
      "Options for selecting the FFT backend and controlling its performance in this program.:\r\n",
      "  --fft-backends [FFT_BACKENDS [FFT_BACKENDS ...]]\r\n",
      "                        Preference list of the FFT backends. Choices are:\r\n",
      "                        ['fftw', 'numpy']\r\n",
      "  --fftw-measure-level FFTW_MEASURE_LEVEL\r\n",
      "                        Determines the measure level used in planning FFTW\r\n",
      "                        FFTs; allowed values are: [0, 1, 2, 3]\r\n",
      "  --fftw-threads-backend FFTW_THREADS_BACKEND\r\n",
      "                        Give 'openmp', 'pthreads' or 'unthreaded' to specify\r\n",
      "                        which threaded FFTW to use\r\n",
      "  --fftw-input-float-wisdom-file FFTW_INPUT_FLOAT_WISDOM_FILE\r\n",
      "                        Filename from which to read single-precision wisdom\r\n",
      "  --fftw-input-double-wisdom-file FFTW_INPUT_DOUBLE_WISDOM_FILE\r\n",
      "                        Filename from which to read double-precision wisdom\r\n",
      "  --fftw-output-float-wisdom-file FFTW_OUTPUT_FLOAT_WISDOM_FILE\r\n",
      "                        Filename to which to write single-precision wisdom\r\n",
      "  --fftw-output-double-wisdom-file FFTW_OUTPUT_DOUBLE_WISDOM_FILE\r\n",
      "                        Filename to which to write double-precision wisdom\r\n",
      "  --fftw-import-system-wisdom\r\n",
      "                        If given, call fftw[f]_import_system_wisdom()\r\n",
      "\r\n",
      "Options for selecting optimization-specific settings:\r\n",
      "  --cpu-affinity CPU_AFFINITY\r\n",
      "                        A set of CPUs on which to run, specified in a format\r\n",
      "                        suitable to pass to taskset.\r\n",
      "  --cpu-affinity-from-env CPU_AFFINITY_FROM_ENV\r\n",
      "                        The name of an enivornment variable containing a set\r\n",
      "                        of CPUs on which to run, specified in a format\r\n",
      "                        suitable to pass to taskset.\r\n",
      "\r\n",
      "Options for selecting the processing scheme in this program.:\r\n",
      "  --processing-scheme PROCESSING_SCHEME\r\n",
      "                        The choice of processing scheme. Choices are ['mkl',\r\n",
      "                        'numpy', 'cpu', 'cuda']. (optional for CPU scheme) The\r\n",
      "                        number of execution threads can be indicated by\r\n",
      "                        cpu:NUM_THREADS, where NUM_THREADS is an integer. The\r\n",
      "                        default is a single thread. If the scheme is provided\r\n",
      "                        as cpu:env, the number of threads can be provided by\r\n",
      "                        the PYCBC_NUM_THREADS environment variable. If the\r\n",
      "                        environment variable is not set, the number of threads\r\n",
      "                        matches the number of logical cores.\r\n",
      "  --processing-device-id PROCESSING_DEVICE_ID\r\n",
      "                        (optional) ID of GPU to use for accelerated processing\r\n"
     ]
    }
   ],
   "source": [
    "!gwnr_create_public_events_pycbc_inference_workflow -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-17 17:49:18,790 Reading configuration file\n",
      "2020-03-17 17:49:18,792 Using seed 0\n",
      "2020-03-17 17:49:18,794 Running with CPU support: 1 threads\n",
      "2020-03-17 17:49:18,904 Will setup analyses in .\n",
      "2020-03-17 17:49:18,906 Making workspace directories\n",
      "2020-03-17 17:49:18,907 Creating DAG\n",
      "2020-03-17 17:49:18,914 Making eventGW170104/emcee_pt/bbh_precessing in /home/prayush/research/test_pycbc_gw150914\n",
      "2020-03-17 17:49:18,984 Copying config files to eventGW170104/emcee_pt/bbh_precessing\n",
      "2020-03-17 17:49:18,986 Copying executables to eventGW170104/emcee_pt/bbh_precessing/scripts/\n",
      "2020-03-17 17:49:18,988 Fetching GWOSC frame data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.gw-openscience.org/catalog/GWTC-1-confident/data/GW170104/H-H1_GWOSC_4KHZ_R1-1167557889-4096.gwf [Done]\n",
      "Downloading https://www.gw-openscience.org/catalog/GWTC-1-confident/data/GW170104/L-L1_GWOSC_4KHZ_R1-1167557889-4096.gwf [Done]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-17 17:50:43,606 Fetching PSD files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://dcc.ligo.org/public/0158/P1900011/001/GWTC1_GW170104_PSDs.dat [Done]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-17 17:51:37,611 Making eventGW150914/emcee_pt/bbh_precessing in /home/prayush/research/test_pycbc_gw150914\n",
      "2020-03-17 17:51:37,701 Copying config files to eventGW150914/emcee_pt/bbh_precessing\n",
      "2020-03-17 17:51:37,704 Copying executables to eventGW150914/emcee_pt/bbh_precessing/scripts/\n",
      "2020-03-17 17:51:37,706 Fetching GWOSC frame data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.gw-openscience.org/catalog/GWTC-1-confident/data/GW150914/H-H1_GWOSC_4KHZ_R1-1126257415-4096.gwf [Done]\n",
      "Downloading https://www.gw-openscience.org/catalog/GWTC-1-confident/data/GW150914/L-L1_GWOSC_4KHZ_R1-1126257415-4096.gwf [Done]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-17 17:52:54,887 Fetching PSD files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://dcc.ligo.org/public/0158/P1900011/001/GWTC1_GW150914_PSDs.dat [Done]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-17 17:53:50,550 Done\n"
     ]
    }
   ],
   "source": [
    "!gwnr_create_public_events_pycbc_inference_workflow --config-files config.ini --output-dir . --force --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[00m\r\n",
      "├── bbh_precessing.ini\r\n",
      "├── config.ini\r\n",
      "├── emcee_pt.ini\r\n",
      "├── \u001b[01;34meventGW150914\u001b[00m\r\n",
      "│   ├── \u001b[01;34mdata\u001b[00m\r\n",
      "│   │   ├── H-H1_GWOSC_4KHZ_R1-1126257415-4096.gwf\r\n",
      "│   │   ├── L-L1_GWOSC_4KHZ_R1-1126257415-4096.gwf\r\n",
      "│   │   ├── psd_H1.dat\r\n",
      "│   │   └── psd_L1.dat\r\n",
      "│   └── \u001b[01;34memcee_pt\u001b[00m\r\n",
      "│       └── \u001b[01;34mbbh_precessing\u001b[00m\r\n",
      "│           ├── data.ini\r\n",
      "│           ├── inference.hdf.bkup\r\n",
      "│           ├── inference.hdf.checkpoint\r\n",
      "│           ├── inference.ini\r\n",
      "│           ├── \u001b[01;34mlog\u001b[00m\r\n",
      "│           │   ├── run_inference-166-0.err\r\n",
      "│           │   ├── run_inference-166-0.out\r\n",
      "│           │   ├── run_inference-169-0.err\r\n",
      "│           │   ├── run_inference-169-0.out\r\n",
      "│           │   ├── run_inference-173-0.err\r\n",
      "│           │   ├── run_inference-173-0.out\r\n",
      "│           │   └── tmpFgLflx\r\n",
      "│           ├── \u001b[01;32mmake_plot_mass1mass2\u001b[00m\r\n",
      "│           ├── make_plot_mass1mass2.sub\r\n",
      "│           ├── \u001b[01;34mplots\u001b[00m\r\n",
      "│           ├── \u001b[01;32mrun_inference\u001b[00m\r\n",
      "│           ├── run_inference.sub\r\n",
      "│           ├── sampler.ini\r\n",
      "│           └── \u001b[01;34mscripts\u001b[00m\r\n",
      "│               ├── \u001b[01;32mpycbc_inference\u001b[00m\r\n",
      "│               └── \u001b[01;32mpycbc_inference_plot_posterior\u001b[00m\r\n",
      "├── \u001b[01;34meventGW170104\u001b[00m\r\n",
      "│   ├── \u001b[01;34mdata\u001b[00m\r\n",
      "│   │   ├── H-H1_GWOSC_4KHZ_R1-1167557889-4096.gwf\r\n",
      "│   │   ├── L-L1_GWOSC_4KHZ_R1-1167557889-4096.gwf\r\n",
      "│   │   ├── psd_H1.dat\r\n",
      "│   │   └── psd_L1.dat\r\n",
      "│   └── \u001b[01;34memcee_pt\u001b[00m\r\n",
      "│       └── \u001b[01;34mbbh_precessing\u001b[00m\r\n",
      "│           ├── data.ini\r\n",
      "│           ├── inference.ini\r\n",
      "│           ├── \u001b[01;34mlog\u001b[00m\r\n",
      "│           │   ├── run_inference-165-0.err\r\n",
      "│           │   ├── run_inference-165-0.out\r\n",
      "│           │   ├── run_inference-168-0.err\r\n",
      "│           │   ├── run_inference-168-0.out\r\n",
      "│           │   ├── run_inference-172-0.err\r\n",
      "│           │   ├── run_inference-172-0.out\r\n",
      "│           │   └── tmpFgLflx\r\n",
      "│           ├── \u001b[01;32mmake_plot_mass1mass2\u001b[00m\r\n",
      "│           ├── make_plot_mass1mass2.sub\r\n",
      "│           ├── \u001b[01;34mplots\u001b[00m\r\n",
      "│           ├── \u001b[01;32mrun_inference\u001b[00m\r\n",
      "│           ├── run_inference.sub\r\n",
      "│           ├── sampler.ini\r\n",
      "│           └── \u001b[01;34mscripts\u001b[00m\r\n",
      "│               ├── \u001b[01;32mpycbc_inference\u001b[00m\r\n",
      "│               └── \u001b[01;32mpycbc_inference_plot_posterior\u001b[00m\r\n",
      "├── \u001b[01;34mlog\u001b[00m\r\n",
      "├── pycbc_inference_events.dag\r\n",
      "├── pycbc_inference_events.dag.condor.sub\r\n",
      "├── pycbc_inference_events.dag.dagman.log\r\n",
      "├── pycbc_inference_events.dag.dagman.out\r\n",
      "├── pycbc_inference_events.dag.lib.err\r\n",
      "├── pycbc_inference_events.dag.lib.out\r\n",
      "├── pycbc_inference_events.dag.lock\r\n",
      "├── pycbc_inference_events.dag.metrics\r\n",
      "├── pycbc_inference_events.dag.nodes.log\r\n",
      "├── pycbc_inference_events.dag.rescue001\r\n",
      "├── pycbc_inference_events.dag.rescue002\r\n",
      "└── \u001b[01;32mpycbc_inference_events.sh\u001b[00m\r\n",
      "\r\n",
      "15 directories, 57 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit & monitor workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!condor_submit_dag pycbc_inference_events.dag >> dag.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/04/20 14:44:41 Workflow accounting_group_user: <>\r\n",
      "03/04/20 14:44:41 Warning: failed to get attribute DAGNodeName\r\n",
      "03/04/20 14:44:41 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False\r\n",
      "03/04/20 14:44:41 Default node log file is: </home/prayush/research/test_pycbc_gw150914/./pycbc_inference_events.dag.nodes.log>\r\n",
      "03/04/20 14:44:41 DAG Lockfile will be written to pycbc_inference_events.dag.lock\r\n",
      "03/04/20 14:44:41 DAG Input file is pycbc_inference_events.dag\r\n",
      "03/04/20 14:44:41 Parsing 1 dagfiles\r\n",
      "03/04/20 14:44:41 Parsing pycbc_inference_events.dag ...\r\n",
      "03/04/20 14:44:41 Dag contains 4 total jobs\r\n",
      "03/04/20 14:44:41 Sleeping for 3 seconds to ensure ProcessId uniqueness\r\n"
     ]
    }
   ],
   "source": [
    "!tail *dagman.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and run Bayesian inference on a batch of GW events using `bilby`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "run_dir = '/home/prayush/research/test_bilby_events'\n",
    "try: os.makedirs(run_dir)\n",
    "except: pass\n",
    "os.chdir(run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prayush/research/test_bilby_events\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate workflow config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prayush/miniconda3/envs/lalsuite-dev/lib/python3.9/site-packages/pandas/core/common.py:208: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n",
      "usage: /home/prayush/miniconda3/envs/lalsuite-dev/lib/python3.9/site-packages/gwnrtools-2020.10.30-py3.9.egg/EGG-INFO/scripts/gwnrtools_write_bilby_configs [--options]\n",
      "\n",
      "Get and write configuration files for generating a workflow to perform\n",
      "Bayesian parameter estimation runs on a custom set of signals with Bilby\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --version             Prints version information.\n",
      "  --verbose             Print logging messages.\n",
      "  --write-config WRITE_CONFIG\n",
      "                        Comma-separated name of config-type,config-subtype,\n",
      "                        e.g.'prior,precessing_spins_bbh'\n",
      "  --write-injection-config WRITE_INJECTION_CONFIG\n",
      "                        Write config files for injections and exit.\n",
      "  --write-event-config WRITE_EVENT_CONFIG\n",
      "                        Write config files for events and exit.\n",
      "  --show-available-configs\n",
      "                        Show available options for all configurations.\n",
      "  --output-dir OUTPUT_DIR\n",
      "                        Output directory path.\n"
     ]
    }
   ],
   "source": [
    "!gwnr_write_bilby_configs --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prayush/miniconda3/envs/lalsuite-dev/lib/python3.9/site-packages/pandas/core/common.py:208: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n",
      "prior: ['default', 'eccentric-nonspin', 'precessing_spins_bns', 'GW170817', 'GW150914', 'precessing_spins_bbh_tides_on', 'aligned_spins_bbh_tides_on', 'precessing_spins_bns_tides_on', 'aligned_spins_bbh', 'precessing_spins_bbh', 'aligned_spins_bns', 'aligned_spins_bns_tides_on']\n",
      "injection: ['bbh-prior-default', 'bbh-alignedspin-prior-default', 'bbh-eccentric-nonspin-prior-default', 'bbh-prior-eccentric-nonspin', 'bbh-alignedspin-prior-eccentric-nonspin', 'bbh-eccentric-nonspin-prior-eccentric-nonspin', 'bbh-prior-precessing_spins_bns', 'bbh-alignedspin-prior-precessing_spins_bns', 'bbh-eccentric-nonspin-prior-precessing_spins_bns', 'bbh-prior-GW170817', 'bbh-alignedspin-prior-GW170817', 'bbh-eccentric-nonspin-prior-GW170817', 'bbh-prior-GW150914', 'bbh-alignedspin-prior-GW150914', 'bbh-eccentric-nonspin-prior-GW150914', 'bbh-prior-precessing_spins_bbh_tides_on', 'bbh-alignedspin-prior-precessing_spins_bbh_tides_on', 'bbh-eccentric-nonspin-prior-precessing_spins_bbh_tides_on', 'bbh-prior-aligned_spins_bbh_tides_on', 'bbh-alignedspin-prior-aligned_spins_bbh_tides_on', 'bbh-eccentric-nonspin-prior-aligned_spins_bbh_tides_on', 'bbh-prior-precessing_spins_bns_tides_on', 'bbh-alignedspin-prior-precessing_spins_bns_tides_on', 'bbh-eccentric-nonspin-prior-precessing_spins_bns_tides_on', 'bbh-prior-aligned_spins_bbh', 'bbh-alignedspin-prior-aligned_spins_bbh', 'bbh-eccentric-nonspin-prior-aligned_spins_bbh', 'bbh-prior-precessing_spins_bbh', 'bbh-alignedspin-prior-precessing_spins_bbh', 'bbh-eccentric-nonspin-prior-precessing_spins_bbh', 'bbh-prior-aligned_spins_bns', 'bbh-alignedspin-prior-aligned_spins_bns', 'bbh-eccentric-nonspin-prior-aligned_spins_bns', 'bbh-prior-aligned_spins_bns_tides_on', 'bbh-alignedspin-prior-aligned_spins_bns_tides_on', 'bbh-eccentric-nonspin-prior-aligned_spins_bns_tides_on']\n",
      "event: ['bbh-event-prior-default', 'bbh-event-prior-eccentric-nonspin', 'bbh-event-prior-precessing_spins_bns', 'bbh-event-prior-GW170817', 'bbh-event-prior-GW150914', 'bbh-event-prior-precessing_spins_bbh_tides_on', 'bbh-event-prior-aligned_spins_bbh_tides_on', 'bbh-event-prior-precessing_spins_bns_tides_on', 'bbh-event-prior-aligned_spins_bbh', 'bbh-event-prior-precessing_spins_bbh', 'bbh-event-prior-aligned_spins_bns', 'bbh-event-prior-aligned_spins_bns_tides_on']\n"
     ]
    }
   ],
   "source": [
    "!gwnr_write_bilby_configs --show-available-configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prayush/miniconda3/envs/lalsuite-dev/lib/python3.9/site-packages/pandas/core/common.py:208: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n",
      "2021-09-20 19:37:00,651 Done\n"
     ]
    }
   ],
   "source": [
    "!gwnr_write_bilby_configs --write-config event,bbh-event-prior-GW150914 --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbh-event-prior-GW150914.ini\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[workflow]\n",
      "tag = test\n",
      "accounting-group = ligo.dev.o3.cbc.explore.test\n",
      "log-path = log\n",
      "request-memory = 2G\n",
      "request-cpus = 1\n",
      "\n",
      "[inference]\n",
      "duration = 4\n",
      "sample_rate = 2048\n",
      "lower_frequency_cutoff = 30\n",
      "upper_frequency_cutoff = 1024\n",
      "reference_frequency = 30\n",
      "phase_marginalization =\n",
      "time_marginalization =\n",
      ";distance_marginalization =\n",
      "\n",
      "[sampler]\n",
      "name = dynesty\n",
      "npoints = 2000\n",
      "maxmcmc = 2000\n",
      "n_check_point = 1000\n",
      "\n",
      "[data]\n",
      "analysis_type = event\n",
      "source_type = bbh\n",
      "event_names = GW150914,GW170104\n",
      "interferometers = H1,L1\n",
      "\n",
      "\n",
      "[template]\n",
      "source_model = bilby.gw.source.lal_binary_black_hole\n",
      "approximant = IMRPhenomPv2\n",
      "sample_rate = 2048\n",
      "lower_frequency_cutoff = 30\n",
      "upper_frequency_cutoff = 1024\n",
      "reference_frequency = 30\n",
      "\n",
      "\n",
      "[prior]\n",
      "mass_ratio = Uniform(name='mass_ratio', minimum=0.125, maximum=1)\n",
      "chirp_mass = Uniform(name='chirp_mass', minimum=25, maximum=31)\n",
      "mass_1 = Constraint(name='mass_1', minimum=10, maximum=80)\n",
      "mass_2 = Constraint(name='mass_2', minimum=10, maximum=80)\n",
      "a_1 = Uniform(name='a_1', minimum=0, maximum=0.99)\n",
      "a_2 = Uniform(name='a_2', minimum=0, maximum=0.99)\n",
      "tilt_1 = Sine(name='tilt_1', boundary='reflective')\n",
      "tilt_2 = Sine(name='tilt_2', boundary='reflective')\n",
      "phi_12 = Uniform(name='phi_12', minimum=0, maximum=2 * np.pi, boundary='periodic')\n",
      "phi_jl = Uniform(name='phi_jl', minimum=0, maximum=2 * np.pi, boundary='periodic')\n",
      "luminosity_distance = PowerLaw(alpha=2, name='luminosity_distance', minimum=50, maximum=2000, unit='Mpc', latex_label='$d_L$')\n",
      "dec =  Cosine(name='dec')\n",
      "ra =  Uniform(name='ra', minimum=0, maximum=2 * np.pi, boundary='periodic')\n",
      "theta_jn =  Sine(name='theta_jn', boundary='reflective')\n",
      "psi =  Uniform(name='psi', minimum=0, maximum=np.pi, boundary='periodic')\n",
      "phase =  Uniform(name='phase', minimum=0, maximum=2 * np.pi, boundary='periodic')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat bbh-event-prior-GW150914.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prayush/miniconda3/envs/lalsuite-dev/lib/python3.9/site-packages/pandas/core/common.py:208: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n",
      "usage: /home/prayush/miniconda3/envs/lalsuite-dev/lib/python3.9/site-packages/gwnrtools-2020.10.30-py3.9.egg/EGG-INFO/scripts/gwnrtools_create_public_events_bilby_workflow [--options]\n",
      "\n",
      "Setup workflow to perform Bayesian parameter estimation runs on a custom set\n",
      "of simulated signals\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --version             Prints version information.\n",
      "  --verbose             Print logging messages.\n",
      "  --config-file CONFIG_FILE\n",
      "                        Configuration file with details of analyses. See\n",
      "                        `gwnrtools_write_bilby_inference_configs` for help.\n",
      "  --output-dir OUTPUT_DIR\n",
      "                        Output directory path.\n",
      "  --force               If the output-dir already exists, overwrite it.\n",
      "                        Otherwise, an OSError is raised.\n",
      "  --save-backup         Don't delete the backup file after the run has\n",
      "                        completed.\n",
      "  --nprocesses NPROCESSES\n",
      "                        Number of processes to use. If not given then only a\n",
      "                        single core will be used.\n",
      "  --use-mpi             Use MPI to parallelize the sampler\n",
      "  --seed SEED           Seed to use for the random number generator that\n",
      "                        initially distributes the walkers. Default is 0.\n"
     ]
    }
   ],
   "source": [
    "!gwnr_create_public_events_bilby_workflow --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prayush/miniconda3/envs/lalsuite-dev/lib/python3.9/site-packages/pandas/core/common.py:208: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n",
      "2021-09-20 19:42:43,113 Using seed 0\n",
      "2021-09-20 19:42:43,130 Will setup analyses in bbh-events\n",
      "2021-09-20 19:42:43,130 Creating DAG\n",
      "2021-09-20 19:42:43,130 --- creating script writer objects for events\n",
      "2021-09-20 19:42:43,131 --- script writer object created for event GW150914\n",
      "2021-09-20 19:42:43,131 --- analysis objects created for event 0\n",
      "2021-09-20 19:42:43,131 --- script writer object created for event GW170104\n",
      "2021-09-20 19:42:43,131 --- analysis objects created for event 1\n",
      "2021-09-20 19:42:43,131 Making ./GW150914 in /home/prayush/research/test_pycbc_gw150914/bbh-events\n",
      "Writing script for event data\n",
      "Please do not forget to write 'priors.prior'\n",
      "2021-09-20 19:42:43,147 Making ./GW170104 in /home/prayush/research/test_pycbc_gw150914/bbh-events\n",
      "Writing script for event data\n",
      "Please do not forget to write 'priors.prior'\n",
      "2021-09-20 19:42:43,162 Done\n"
     ]
    }
   ],
   "source": [
    "!gwnr_create_public_events_bilby_workflow --config-file bbh-event-prior-GW150914.ini --output-dir bbh-events --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[00m\n",
      "├── bbh-event-prior-GW150914.ini\n",
      "├── \u001b[01;34mbbh-events\u001b[00m\n",
      "│   ├── bbh-event-prior-GW150914.ini\n",
      "│   ├── bilby_events.dag\n",
      "│   ├── \u001b[01;32mbilby_events.sh\u001b[00m\n",
      "│   ├── \u001b[01;34mGW150914\u001b[00m\n",
      "│   │   ├── \u001b[01;34mlog\u001b[00m\n",
      "│   │   ├── priors.prior\n",
      "│   │   ├── \u001b[01;32mrun_inference\u001b[00m\n",
      "│   │   └── run_inference.sub\n",
      "│   └── \u001b[01;34mGW170104\u001b[00m\n",
      "│       ├── \u001b[01;34mlog\u001b[00m\n",
      "│       ├── priors.prior\n",
      "│       ├── \u001b[01;32mrun_inference\u001b[00m\n",
      "│       └── run_inference.sub\n",
      "├── bbh_precessing.ini\n",
      "└── emcee_pt.ini\n",
      "\n",
      "5 directories, 12 files\n"
     ]
    }
   ],
   "source": [
    "!tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit & monitor workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbh-event-prior-GW150914.ini  bilby_events.sh  GW170104\n",
      "bilby_events.dag\t      GW150914\n"
     ]
    }
   ],
   "source": [
    "os.chdir('bbh-events')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!condor_submit_dag bilby_events.dag >> dag.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/20/21 19:46:08 Number of idle job procs: 1\n",
      "09/20/21 19:46:08 Reassigning the id of job 23e9b16444d8cf36712e2be1b5c18c7d from (112.0.0) to (112.0.0)\n",
      "09/20/21 19:46:08 Event: ULOG_SUBMIT for HTCondor Node 23e9b16444d8cf36712e2be1b5c18c7d (112.0.0) {09/20/21 19:46:08}\n",
      "09/20/21 19:46:08 Number of idle job procs: 2\n",
      "09/20/21 19:46:08 DAG status: 0 (DAG_STATUS_OK)\n",
      "09/20/21 19:46:08 Of 2 nodes total:\n",
      "09/20/21 19:46:08  Done     Pre   Queued    Post   Ready   Un-Ready   Failed\n",
      "09/20/21 19:46:08   ===     ===      ===     ===     ===        ===      ===\n",
      "09/20/21 19:46:08     0       0        2       0       0          0        0\n",
      "09/20/21 19:46:08 0 job proc(s) currently held\n"
     ]
    }
   ],
   "source": [
    "!tail *dagman.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5208ffcf4e66d11154eccba892d9e5910a71e80c2a7c3160a1f8442f3e16d89b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('lalsuite-dev': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
