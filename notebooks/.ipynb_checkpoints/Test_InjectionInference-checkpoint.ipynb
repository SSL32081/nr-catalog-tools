{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing `pycbc_inference` workflow generator for batch of injections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> **ALGORITHM**\n",
    "\n",
    ">> **Requirements**:\n",
    " 1. Take as input **one** `injection.ini` with configuration options to generate a list of\n",
    "     appropriate injections.\n",
    "     - This is passed onto `pycbc_create_injections` with a new seed for every run\n",
    " 2. Take as input **multiple** `data.ini`:\n",
    "     - Each can have different ways of configuring data (noise vs no-noise)\n",
    " 3. Take as input **multiple** `sampler.ini`:\n",
    "     - Each can have different samplers configured\n",
    " 4. Take as input **multiple** `inference.ini` with options for the `pycbc_inference` jobs.\n",
    "     - Each `inference.ini` can use different sampling priors and `model`s,\n",
    " 3. Take as input **one** `config.ini` with configuration options for the workflow\n",
    "     - Specifies which `inference???.ini` to use\n",
    "     - Specifies which `data???.ini` to use\n",
    "     - Specifies which `sampler???.ini` to use\n",
    "     - Specifies which `inference???.ini` to use\n",
    "     - Each subset of injections will have a full set of operations,\n",
    "     - A new directory structure is created as:\n",
    "         - `${ROOT}/injNNNNNN/` ...\n",
    "\n",
    "\n",
    ">>> **Outline**:\n",
    " 1. Read in `config.ini` and parse it. \n",
    " 1. Say the user asks for `N` injections, `D` different data configs, `S` different samplers, and `M` different inferencing combinations. We have a total of `N x D x S x M` independent runs.\n",
    " 1. Create subdirs `injection???` for each of the `N` physically distinct injections.\n",
    " 1. Create `D` subdirs of each of those for each data config\n",
    " 1. Create `S` subdirs of each of those for each sampler type\n",
    " 1. Create `M` subdirs of each of those for each model / prior set\n",
    " 1. Run directory for each injection is `injection???/data???/sampler???/model???`\n",
    " 1. Copy over `injection.ini` (common for all injections) to `injection???/data???/sampler???/model???`\n",
    " 1. Copy over the relevant `data.ini`, `sampler.ini` and `inference???.ini` as `inference.ini`\n",
    " 1. Create run script for creating the injection. Call it `make_injection.sh`\n",
    " 1. Create run script for running `pycbc_inference` on it. Call it `run_inference.sh`.\n",
    " 1. Create `2` `BaseJob`s PER injection + inference combination, and make the former a parent job. **Use fresh seed for the injection job**.\n",
    " 1. Add both jobs as nodes to the `DAG`\n",
    " 1. **SUBMIT** the `DAG` to chosen scheduler: condor or slurm;\n",
    "      - All jobs at once? : of course!\n",
    "      - Do we check if an analysis is running? : yes, for the `DAG` only though!\n",
    "      - Do we resume? Or, do we kill and restart all forcefully? (BAD IDEA)\n",
    "          - Is `pycbc_inference` able to resume **correctly** yet?\n",
    "\n",
    "\n",
    "**NOTE**: Steps`9-11` assume `Condor`! Upgrade to use `Slurm` later.\n",
    "\n",
    ">> **Implementation**:\n",
    " 1. `DAG` managed through `glue`,\n",
    " 2. `CondorJob` managed through `BaseJob`,\n",
    " 3. Way to define variables in equivalent representation,\n",
    " \n",
    "\n",
    ">>> **Technical**\n",
    " 1. Directory structure for all jobs ... ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prayush/local/venv/pycbc_inf/local/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['rc']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not import ligolw in /home/prayush/src/GWNRTools/GWNRTools/Stats/FisherMatrixUtilities.pyc, LIGO XML tables wont be read\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('text', usetex = True)\n",
    "\n",
    "plt.rcParams.update(  # try to match font sizes of document\n",
    "  {'axes.labelsize': 20,\n",
    "   'axes.titlesize': 20,\n",
    "   'legend.fontsize': 20,\n",
    "   'xtick.labelsize': 20,\n",
    "   'ytick.labelsize': 20,\n",
    "   'text.usetex': True,\n",
    "   'font.family': 'serif',\n",
    "   'font.serif': ['palatino'],\n",
    "   'savefig.dpi': 300\n",
    "   })\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "from glue.ligolw import ligolw\n",
    "from glue.ligolw import table\n",
    "from glue.ligolw import lsctables\n",
    "from glue.ligolw import ilwd\n",
    "from glue.ligolw import utils as ligolw_utils\n",
    "\n",
    "import pycbc.strain\n",
    "import pycbc.psd\n",
    "from pycbc.pnutils import mass1_mass2_to_mchirp_eta\n",
    "from pycbc.waveform import td_approximants, fd_approximants\n",
    "from pycbc.waveform import get_two_pol_waveform_filter, get_td_waveform\n",
    "from pycbc import DYN_RANGE_FAC\n",
    "from pycbc.types import FrequencySeries, zeros\n",
    "from pycbc.filter import match, overlap, sigma, make_frequency_series\n",
    "from pycbc.scheme import CPUScheme, CUDAScheme\n",
    "from pycbc import pnutils\n",
    "\n",
    "from GWNRTools.Utils.SupportFunctions import make_padded_frequency_series\n",
    "from GWNRTools.DataAnalysis import get_unique_hex_tag\n",
    "import GWNRTools.DataAnalysis as DA\n",
    "\n",
    "sys.path.append('/home/prayush.kumar/src/GWNRTools/bin/')\n",
    "sys.path.append('/home/prayush/src/GWNRTools/bin/')\n",
    "#sys.path.append('/home/prayush.kumar/local/venv/pycbc_master_enigma/src/GWNRTools/bin/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run_dir = '/home/prayush/research/test_pycbc_inf'\n",
    "try: os.makedirs(run_dir)\n",
    "except: pass\n",
    "os.chdir(run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.ini\t\t    make_inj.sh\r\n",
      "emcee_pt-gw150914_like.ini  output_strain_after_inj0.txt\r\n",
      "gw150914_like.ini\t    output_strain_after_inj2.txt\r\n",
      "inference.hdf.bkup\t    output_strain_after_inj4.txt\r\n",
      "inference.hdf.checkpoint    output_strain_after_inj6.txt\r\n",
      "injection.10.hdf\t    output_strain_after_inj8.txt\r\n",
      "injection.hdf\t\t    output_strain.txt\r\n",
      "injection.ini\t\t    run.sh\r\n",
      "input_strain.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Injector scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(\"injection.ini\", \"w\") as fout:\n",
    "    fout.write(\"\"\"\\\n",
    "[static_params]\n",
    "tc = 1126259462.420\n",
    ";mass1 = 37\n",
    "mass2 = 32\n",
    "ra = 2.2\n",
    "dec = -1.25\n",
    "inclination = 2.5\n",
    "coa_phase = 1.5\n",
    "polarization = 1.75\n",
    "distance = 100\n",
    "f_ref = 20\n",
    "f_lower = 18\n",
    "approximant = ENIGMA\n",
    "taper = start\n",
    "\n",
    "[variable_params]\n",
    "mass1 =\n",
    "eccentricity =\n",
    "mean_per_ano =\n",
    "\n",
    "[prior-mass1]\n",
    "name = uniform\n",
    "min-mass1 = 10.\n",
    "max-mass1 = 80.\n",
    "\n",
    "[prior-eccentricity]\n",
    "name = uniform\n",
    "min-eccentricity = 0.\n",
    "max-eccentricity = 0.2\n",
    "\n",
    "[prior-mean_per_ano]\n",
    "name = uniform\n",
    "min-mean_per_ano = 0.\n",
    "max-mean_per_ano = 3.1416\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!cat injection.ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(\"make_inj.sh\", \"w\") as fout:\n",
    "    fout.write(\"\"\"#!/bin/sh\n",
    "pycbc_create_injections --verbose \\\\\n",
    "        --config-files injection.ini \\\\\n",
    "        --ninjections 10 \\\\\n",
    "        --seed 10 \\\\\n",
    "        --output-file injection.hdf \\\\\n",
    "        --variable-params-section variable_params \\\\\n",
    "        --static-params-section static_params \\\\\n",
    "        --dist-section prior \\\\\n",
    "        --force\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!cat make_inj.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!./make_inj.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!h5ls -rv injection.hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pycbc.inject import InjectionSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inj = InjectionSet(\"injection.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for r in inj.table:\n",
    "    print r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for n in r.dtype.names:print(n, r[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inj_f = h5py.File('injection.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inj_f.attrs['mass2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inj_f['mass1'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inj_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "opt = (analysis_end_time=2,\n",
    "       analysis_start_time=-6,\n",
    "       asd_file=None,\n",
    "       autogating_cluster=5.0,\n",
    "       autogating_max_iterations=1,\n",
    "       autogating_pad=16, autogating_taper=0.25, autogating_threshold=None, autogating_width=0.25,\n",
    "       channel_name='H1:STRAIN',\n",
    "       dq_segment_name='DATA', dq_server='segments.ligo.org', dq_source='any',\n",
    "       fake_strain='aLIGOaLIGODesignSensitivityT1800044',\n",
    "       fake_strain_from_file=None, fake_strain_seed=44,\n",
    "       frame_cache=None, frame_files=None, frame_sieve=None, frame_type=None,\n",
    "       gate=None, gate_overwhitened=False, gating_file=None,\n",
    "       gps_end_time=1126259468, gps_start_time=1126259452,\n",
    "       hdf_store=None,\n",
    "       injection_f_final=None, injection_f_ref=None,\n",
    "       injection_file='injection.hdf', injection_scale_factor=1.0,\n",
    "       instruments=['H1', 'L1'],\n",
    "       low_frequency_cutoff=20.0,\n",
    "       normalize_strain=None, pad_data=8,\n",
    "       psd_end_time=1126259718, psd_estimation='median-mean', psd_file=None,\n",
    "       psd_gate=None, psd_inverse_length=8.0, psd_model=None, psd_num_segments=None,\n",
    "       psd_output=None, psd_segment_length=8.0, psd_segment_stride=4.0,\n",
    "       psd_start_time=1126259206, psdvar_high_freq=None, psdvar_long_segment=None,\n",
    "       psdvar_low_freq=None, psdvar_psd_duration=None, psdvar_psd_stride=None, psdvar_segment=None,\n",
    "       psdvar_short_segment=None,\n",
    "       sample_rate=2048,\n",
    "       sgburst_injection_file=None,\n",
    "       strain_high_pass=15.0, taper_data=0,\n",
    "       trigger_time=1126259462, veto_definer=None, zpk_k=None, zpk_p=None, zpk_z=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!ls *txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inj_tc = 1126259462.420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "in_s = np.loadtxt('input_strain.txt')\n",
    "out_s = np.loadtxt('output_strain.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inj_s = {}\n",
    "for ii in range(10):\n",
    "    print(\"Making figure for injection {}\".format(ii))\n",
    "    inj_s[ii] = np.loadtxt('output_strain_after_inj{}.txt'.format(ii))\n",
    "    \n",
    "    figure(figsize = (12, 5))\n",
    "    plot(in_s[:,0], in_s[:,1], alpha = 0.4, label = 'input')\n",
    "    plot(inj_s[ii][:,0], inj_s[ii][:,1], alpha = 0.6, label = 'output')\n",
    "    \n",
    "    xlim(inj_tc - 8, inj_tc + 2)\n",
    "    ylim( -2e-20, 2e-20 )\n",
    "    legend(loc = 'best')\n",
    "    grid()\n",
    "    title('INJECTION {}'.format(ii))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    ">> **DECISION**: We will generate a new `injection.hdf` for each individual run,\n",
    "even if the intrinsic parameters of the injection are common amongst many.\n",
    ">>> **pros**: Each `pycbc_inference` run remains self-contained and independent.<br>\n",
    ">>> **cons**: Redundant calls to `pycbc_create_injections`, but this is a one-time cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> **`ConfigWriter`**:\n",
    "> - takes in an `opts` object that contains info on sections and options\n",
    "> - writes them to desired output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ConfigWriter():\n",
    "    def __init__(self, opts, run_dir):\n",
    "        self.opts = opts\n",
    "        self.run_dir = run_dir\n",
    "    def write(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> **`InferenceConfigs`**:\n",
    "> - stores all `config.ini` files\n",
    "> - returns on demand. Compatible with ConfigWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# InferenceConfigs\n",
    "class InferenceConfigs():\n",
    "    def __init__(self, opts, run_dir, configs = {}):\n",
    "        '''\n",
    " - stores all config.ini files\n",
    " - returns on demand. Compatible with ConfigWriter\n",
    "        '''\n",
    "        self.opts = opts\n",
    "        self.run_dir = run_dir\n",
    "        # Make this >>\n",
    "        assert(isinstance(configs, dict))\n",
    "        self.configs = configs\n",
    "        self.configs['data'] = \"\"\"\\\n",
    "[data]\n",
    "instruments = H1 L1\n",
    "trigger-time = 1126259462.42\n",
    "analysis-start-time = -6\n",
    "analysis-end-time = 2\n",
    "; strain settings\n",
    "sample-rate = 2048\n",
    "fake-strain = H1:aLIGOaLIGODesignSensitivityT1800044 L1:aLIGOaLIGODesignSensitivityT1800044\n",
    "fake-strain-seed = H1:44 L1:45\n",
    "; psd settings\n",
    "psd-estimation = median-mean\n",
    "psd-inverse-length = 8\n",
    "psd-segment-length = 8\n",
    "psd-segment-stride = 4\n",
    "psd-start-time = -256\n",
    "psd-end-time = 256\n",
    "; even though we're making fake strain, the strain\n",
    "; module requires a channel to be provided, so we'll\n",
    "; just make one up\n",
    "channel-name = H1:STRAIN L1:STRAIN\n",
    "; Providing an injection file will cause a simulated\n",
    "; signal to be added to the data\n",
    "injection-file = injection.hdf\n",
    "; We'll use a high-pass filter so as not to get numerical errors from the large\n",
    "; amplitude low frequency noise. Here we use 15 Hz, which is safely below the\n",
    "; low frequency cutoff of our likelihood integral (20 Hz)\n",
    "strain-high-pass = 15\n",
    "; The pad-data argument is for the high-pass filter: 8s are added to the\n",
    "; beginning/end of the analysis/psd times when the data is loaded. After the\n",
    "; high pass filter is applied, the additional time is discarded. This pad is\n",
    "; *in addition to* the time added to the analysis start/end time for the PSD\n",
    "; inverse length. Since it is discarded before the data is transformed for the\n",
    "; likelihood integral, it has little affect on the run time.\n",
    "pad-data = 8\n",
    "\"\"\"\n",
    "        self.configs['emcee_pt-gw150914_like'] = \"\"\"\\\n",
    "[sampler]\n",
    "name = emcee_pt\n",
    "nwalkers = 200\n",
    "ntemps = 20\n",
    "effective-nsamples = 1000\n",
    "checkpoint-interval = 2000\n",
    "max-samples-per-chain = 1000\n",
    "\n",
    "[sampler-burn_in]\n",
    "burn-in-test = nacl & max_posterior\n",
    "\n",
    ";\n",
    ";   Sampling transforms\n",
    ";\n",
    "[sampling_params]\n",
    "; parameters on the left will be sampled in\n",
    "; parametes on the right\n",
    "mass1, mass2 : mchirp, q\n",
    "\n",
    "[sampling_transforms-mchirp+q]\n",
    "; inputs mass1, mass2\n",
    "; outputs mchirp, q\n",
    "name = mass1_mass2_to_mchirp_q\n",
    "\"\"\"\n",
    "        self.configs['gw150914_like'] = \"\"\"\\\n",
    "[model]\n",
    "name = gaussian_noise\n",
    "low-frequency-cutoff = 20.0\n",
    "\n",
    "[variable_params]\n",
    "; waveform parameters that will vary in MCMC\n",
    "delta_tc =\n",
    "mass1 =\n",
    "mass2 =\n",
    "spin1_a =\n",
    "spin1_azimuthal =\n",
    "spin1_polar =\n",
    "spin2_a =\n",
    "spin2_azimuthal =\n",
    "spin2_polar =\n",
    "distance =\n",
    "coa_phase =\n",
    "inclination =\n",
    "polarization =\n",
    "ra =\n",
    "dec =\n",
    "\n",
    "[static_params]\n",
    "; waveform parameters that will not change in MCMC\n",
    "approximant = ENIGMA\n",
    "f_lower = 20\n",
    "f_ref = 20\n",
    "; we'll set the tc by using the trigger time in the data\n",
    "; section of the config file + delta_tc\n",
    "trigger_time = ${data|trigger-time}\n",
    "\n",
    "[prior-delta_tc]\n",
    "; coalescence time prior\n",
    "name = uniform\n",
    "min-delta_tc = -0.1\n",
    "max-delta_tc = 0.1\n",
    "\n",
    "[waveform_transforms-tc]\n",
    "; we need to provide tc to the waveform generator\n",
    "name = custom\n",
    "inputs = delta_tc\n",
    "tc = ${data|trigger-time} + delta_tc\n",
    "\n",
    "[prior-mass1]\n",
    "name = uniform\n",
    "min-mass1 = 10.\n",
    "max-mass1 = 80.\n",
    "\n",
    "[prior-mass2]\n",
    "name = uniform\n",
    "min-mass2 = 10.\n",
    "max-mass2 = 80.\n",
    "\n",
    "[prior-spin1_a]\n",
    "name = uniform\n",
    "min-spin1_a = 0.0\n",
    "max-spin1_a = 0.99\n",
    "\n",
    "[prior-spin1_polar+spin1_azimuthal]\n",
    "name = uniform_solidangle\n",
    "polar-angle = spin1_polar\n",
    "azimuthal-angle = spin1_azimuthal\n",
    "\n",
    "[prior-spin2_a]\n",
    "name = uniform\n",
    "min-spin2_a = 0.0\n",
    "max-spin2_a = 0.99\n",
    "\n",
    "[prior-spin2_polar+spin2_azimuthal]\n",
    "name = uniform_solidangle\n",
    "polar-angle = spin2_polar\n",
    "azimuthal-angle = spin2_azimuthal\n",
    "\n",
    "[prior-distance]\n",
    "; following gives a uniform volume prior\n",
    "name = uniform_radius\n",
    "min-distance = 10\n",
    "max-distance = 1000\n",
    "\n",
    "[prior-coa_phase]\n",
    "; coalescence phase prior\n",
    "name = uniform_angle\n",
    "\n",
    "[prior-inclination]\n",
    "; inclination prior\n",
    "name = sin_angle\n",
    "\n",
    "[prior-ra+dec]\n",
    "; sky position prior\n",
    "name = uniform_sky\n",
    "\n",
    "[prior-polarization]\n",
    "; polarization prior\n",
    "name = uniform_angle\n",
    "\"\"\"\n",
    "        self.config_names = self.configs.keys()\n",
    "        \n",
    "        self.config_writers = {}\n",
    "        for config_name in self.config_names:\n",
    "            self.config_writers[config_name] = ConfigWriter(opts, run_dir)\n",
    "    def available_configs(self):\n",
    "        return self.config_names\n",
    "    def get(self, config_name):\n",
    "        return self.configs[config_name]\n",
    "    def set(self, config_name, config):\n",
    "        self.configs[config_name] = configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> **`InjectionInferenceAnalysis`**:\n",
    "> - setup individual analysis dir\n",
    "> - setup all analysis dirs\n",
    "> - start / stop / restart individual analysis\n",
    "> - check status of individual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['executables', 'workflow', 'inspinj']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs.sections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data.ini']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs.get('workflow', 'data').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sampler.ini', 'sampler2.ini']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs.get('workflow', 'sampler').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from six.moves import configparser as ConfigParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sampler_configs = {}\n",
    "for f in confs.get('workflow', 'sampler').split():\n",
    "    sampler_configs[f] = ConfigParser.ConfigParser()\n",
    "    sampler_configs[f].read(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      ";      SAMPLER\r\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      "[sampler]\r\n",
      "name = emcee_pt\r\n",
      "nwalkers = 200\r\n",
      "ntemps = 20\r\n",
      "effective-nsamples = 1000\r\n",
      "checkpoint-interval = 2000\r\n",
      "max-samples-per-chain = 1000\r\n",
      "\r\n",
      "[sampler-burn_in]\r\n",
      "burn-in-test = nacl & max_posterior\r\n",
      "\r\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      ";   Sampling transforms\r\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      "[sampling_params]\r\n",
      "; parameters on the left will be sampled in\r\n",
      "; parametes on the right\r\n",
      "mass1, mass2 : mchirp, q\r\n",
      "\r\n",
      "[sampling_transforms-mchirp+q]\r\n",
      "; inputs mass1, mass2\r\n",
      "; outputs mchirp, q\r\n",
      "name = mass1_mass2_to_mchirp_q\r\n"
     ]
    }
   ],
   "source": [
    "!cat sampler.ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cp = sampler_configs['sampler2.ini']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sampler',\n",
       " 'sampler-burn_in',\n",
       " 'sampling_params',\n",
       " 'sampling_transforms-mchirp+q']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.sections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampler\n",
      "[('name', 'emcee_pt'), ('nwalkers', '200'), ('ntemps', '20'), ('effective-nsamples', '1000'), ('checkpoint-interval', '2000'), ('max-samples-per-chain', '1000')]\n",
      "sampler-burn_in\n",
      "[('burn-in-test', 'nacl & max_posterior')]\n",
      "sampling_params\n",
      "[('mass1, mass2', 'mchirp, q')]\n",
      "sampling_transforms-mchirp+q\n",
      "[('name', 'mass1_mass2_to_mchirp_q')]\n"
     ]
    }
   ],
   "source": [
    "for s in cp.sections():\n",
    "    print(s)\n",
    "    print(cp.items(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inspinj', '/home/prayush/local/venv/pycbc_inf/bin/pycbc_create_injections'),\n",
       " ('inference', '/home/prayush/local/venv/pycbc_inf/bin/pycbc_inference')]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs.items('executables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('config', 'injection.ini'),\n",
       " ('ninjections', '10'),\n",
       " ('seed', '1234'),\n",
       " ('output-file', 'injection.hdf'),\n",
       " ('variable-params-section', 'variable_params'),\n",
       " ('static-params-section', 'static_params'),\n",
       " ('dist-section prior', ''),\n",
       " ('force', '')]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs.items('inspinj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "confs.set('inspinj', 'seed', '1234')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_local_dir_change():\n",
    "    idir = os.getcwd()\n",
    "    print(idir)\n",
    "    os.chdir('/home/prayush/research/')\n",
    "    print(os.getcwd())    \n",
    "    os.chdir(idir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prayush/research\n",
      "/home/prayush/research\n"
     ]
    }
   ],
   "source": [
    "test_local_dir_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3274"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(10, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/prayush/research/test_pycbc_inf2'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'data.ini'.split('.ini')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data.ini', 'sampler.ini', 'model.ini')\n",
      "('data.ini', 'sampler2.ini', 'model.ini')\n",
      "('data2.ini', 'sampler.ini', 'model.ini')\n",
      "('data2.ini', 'sampler2.ini', 'model.ini')\n"
     ]
    }
   ],
   "source": [
    "for p in itertools.product(['data.ini', 'data2.ini'], ['sampler.ini', 'sampler2.ini'], ['model.ini']):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data.ini', 'sampler.ini', 'model.ini'),\n",
       " ('data.ini', 'sampler2.ini', 'model.ini'),\n",
       " ('data2.ini', 'sampler.ini', 'model.ini'),\n",
       " ('data2.ini', 'sampler2.ini', 'model.ini')]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.product(['data.ini', 'data2.ini'], ['sampler.ini', 'sampler2.ini'], ['model.ini']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "confs['x'], confs['y'], confs['z'] = ['data.ini', 'data2.ini', 'data3.ini']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inspinj', '/home/prayush/local/venv/pycbc_inf/bin/pycbc_create_injections'),\n",
       " ('inference', '/home/prayush/local/venv/pycbc_inf/bin/pycbc_inference')]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs.items('executables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('data.ini', 'r') as d:\n",
    "    x = d.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('/home/prayush/test.ini', 'w') as f:\n",
    "    f.write(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!git diff --no-index data.ini /home/prayush/test.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glue.pipeline import CondorDAGJob, CondorDAGNode, CondorDAG, CondorJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prayush/research/test_pycbc_inf\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/prayush/research//test_pycbc_inf2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.ini  delme\t   injection.ini  plots\t\tsampler.ini\r\n",
      "data.ini    inference.ini  log\t\t  sampler2.ini\tscripts\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Write CONFIGS\n",
    "with open(\"injection.ini\", \"w\") as fout:\n",
    "    fout.write(\"\"\"\\\n",
    "[static_params]\n",
    "tc = 1126259462.420\n",
    ";mass1 = 37\n",
    "mass2 = 32\n",
    "ra = 2.2\n",
    "dec = -1.25\n",
    "inclination = 2.5\n",
    "coa_phase = 1.5\n",
    "polarization = 1.75\n",
    "distance = 100\n",
    "f_ref = 20\n",
    "f_lower = 18\n",
    "approximant = ENIGMA\n",
    "taper = start\n",
    "\n",
    "[variable_params]\n",
    "mass1 =\n",
    "eccentricity =\n",
    "mean_per_ano =\n",
    "\n",
    "[prior-mass1]\n",
    "name = uniform\n",
    "min-mass1 = 10.\n",
    "max-mass1 = 80.\n",
    "\n",
    "[prior-eccentricity]\n",
    "name = uniform\n",
    "min-eccentricity = 0.\n",
    "max-eccentricity = 0.2\n",
    "\n",
    "[prior-mean_per_ano]\n",
    "name = uniform\n",
    "min-mean_per_ano = 0.\n",
    "max-mean_per_ano = 3.1416\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# data.ini\n",
    "with open(\"data.ini\", \"w\") as fout:\n",
    "    fout.write(\"\"\"\\\n",
    "[data]\n",
    "instruments = H1 L1\n",
    "trigger-time = 1126259462.42\n",
    "analysis-start-time = -6\n",
    "analysis-end-time = 2\n",
    "; strain settings\n",
    "sample-rate = 2048\n",
    "fake-strain = H1:aLIGOaLIGODesignSensitivityT1800044 L1:aLIGOaLIGODesignSensitivityT1800044\n",
    "fake-strain-seed = H1:44 L1:45\n",
    "; psd settings\n",
    "psd-estimation = median-mean\n",
    "psd-inverse-length = 8\n",
    "psd-segment-length = 8\n",
    "psd-segment-stride = 4\n",
    "psd-start-time = -256\n",
    "psd-end-time = 256\n",
    "; even though we're making fake strain, the strain\n",
    "; module requires a channel to be provided, so we'll\n",
    "; just make one up\n",
    "channel-name = H1:STRAIN L1:STRAIN\n",
    "; Providing an injection file will cause a simulated\n",
    "; signal to be added to the data\n",
    "injection-file = injection.hdf\n",
    "; We'll use a high-pass filter so as not to get numerical errors from the large\n",
    "; amplitude low frequency noise. Here we use 15 Hz, which is safely below the\n",
    "; low frequency cutoff of our likelihood integral (20 Hz)\n",
    "strain-high-pass = 15\n",
    "; The pad-data argument is for the high-pass filter: 8s are added to the\n",
    "; beginning/end of the analysis/psd times when the data is loaded. After the\n",
    "; high pass filter is applied, the additional time is discarded. This pad is\n",
    "; *in addition to* the time added to the analysis start/end time for the PSD\n",
    "; inverse length. Since it is discarded before the data is transformed for the\n",
    "; likelihood integral, it has little affect on the run time.\n",
    "pad-data = 8\n",
    "\"\"\")\n",
    "    \n",
    "\n",
    "# sampler.ini\n",
    "with open(\"sampler.ini\", \"w\") as fout:\n",
    "    fout.write(\"\"\"\\\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";      SAMPLER\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "[sampler]\n",
    "name = emcee_pt\n",
    "nwalkers = 200\n",
    "ntemps = 20\n",
    "effective-nsamples = 1000\n",
    "checkpoint-interval = 2000\n",
    "max-samples-per-chain = 1000\n",
    "\n",
    "[sampler-burn_in]\n",
    "burn-in-test = nacl & max_posterior\n",
    "\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";   Sampling transforms\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "[sampling_params]\n",
    "; parameters on the left will be sampled in\n",
    "; parametes on the right\n",
    "mass1, mass2 : mchirp, q\n",
    "\n",
    "[sampling_transforms-mchirp+q]\n",
    "; inputs mass1, mass2\n",
    "; outputs mchirp, q\n",
    "name = mass1_mass2_to_mchirp_q\n",
    "\"\"\")\n",
    "\n",
    "subprocess.call(['cp', '-v', 'sampler.ini', 'sampler2.ini'])\n",
    "\n",
    "# inference.ini\n",
    "with open(\"inference.ini\", \"w\") as fout:\n",
    "    fout.write(\"\"\"\\\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";   Model\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "[model]\n",
    "name = gaussian_noise\n",
    "low-frequency-cutoff = 20.0\n",
    "\n",
    "\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";   Sampling parameters\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "[variable_params]\n",
    "; waveform parameters that will vary in MCMC\n",
    "delta_tc =\n",
    "mass1 =\n",
    "mass2 =\n",
    "spin1_a =\n",
    "spin1_azimuthal =\n",
    "spin1_polar =\n",
    "spin2_a =\n",
    "spin2_azimuthal =\n",
    "spin2_polar =\n",
    "distance =\n",
    "coa_phase =\n",
    "inclination =\n",
    "polarization =\n",
    "ra =\n",
    "dec =\n",
    "\n",
    "[static_params]\n",
    "; waveform parameters that will not change in MCMC\n",
    "approximant = IMRPhenomPv2\n",
    "f_lower = 20\n",
    "f_ref = 20\n",
    "; we'll set the tc by using the trigger time in the data\n",
    "; section of the config file + delta_tc\n",
    "trigger_time = ${data|trigger-time}\n",
    "\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";   Sampling priors\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "[prior-delta_tc]\n",
    "; coalescence time prior\n",
    "name = uniform\n",
    "min-delta_tc = -0.1\n",
    "max-delta_tc = 0.1\n",
    "\n",
    "[waveform_transforms-tc]\n",
    "; we need to provide tc to the waveform generator\n",
    "name = custom\n",
    "inputs = delta_tc\n",
    "tc = ${data|trigger-time} + delta_tc\n",
    "\n",
    "[prior-mass1]\n",
    "name = uniform\n",
    "min-mass1 = 10.\n",
    "max-mass1 = 80.\n",
    "\n",
    "[prior-mass2]\n",
    "name = uniform\n",
    "min-mass2 = 10.\n",
    "max-mass2 = 80.\n",
    "\n",
    "[prior-spin1_a]\n",
    "name = uniform\n",
    "min-spin1_a = 0.0\n",
    "max-spin1_a = 0.99\n",
    "\n",
    "[prior-spin1_polar+spin1_azimuthal]\n",
    "name = uniform_solidangle\n",
    "polar-angle = spin1_polar\n",
    "azimuthal-angle = spin1_azimuthal\n",
    "\n",
    "[prior-spin2_a]\n",
    "name = uniform\n",
    "min-spin2_a = 0.0\n",
    "max-spin2_a = 0.99\n",
    "\n",
    "[prior-spin2_polar+spin2_azimuthal]\n",
    "name = uniform_solidangle\n",
    "polar-angle = spin2_polar\n",
    "azimuthal-angle = spin2_azimuthal\n",
    "\n",
    "[prior-distance]\n",
    "; following gives a uniform volume prior\n",
    "name = uniform_radius\n",
    "min-distance = 10\n",
    "max-distance = 1000\n",
    "\n",
    "[prior-coa_phase]\n",
    "; coalescence phase prior\n",
    "name = uniform_angle\n",
    "\n",
    "[prior-inclination]\n",
    "; inclination prior\n",
    "name = sin_angle\n",
    "\n",
    "[prior-ra+dec]\n",
    "; sky position prior\n",
    "name = uniform_sky\n",
    "\n",
    "[prior-polarization]\n",
    "; polarization prior\n",
    "name = uniform_angle\n",
    "\"\"\")\n",
    "\n",
    "# Workflow.ini\n",
    "with open(\"config.ini\", \"w\") as fout:\n",
    "    fout.write(\"\"\"\\\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";   Executables\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "[executables]\n",
    "inspinj = ${which:pycbc_create_injections}\n",
    "inference = ${which:pycbc_inference}\n",
    "plot = ${which:pycbc_inference_plot_posterior}\n",
    "\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";   Workflow\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "[workflow]\n",
    "accounting-group = ligo.dev.o3.cbc.explore.test\n",
    "templates-per-job = 100\n",
    "log-path = log\n",
    "banksim-request-memory = 8G\n",
    "data = data.ini\n",
    "sampler = sampler.ini sampler2.ini\n",
    "inference = inference.ini\n",
    "\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";   Injections\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "[inspinj]\n",
    "config-files = injection.ini\n",
    "ninjections = 10\n",
    "seed = 10\n",
    "output-file = injection.hdf\n",
    "variable-params-section = variable_params\n",
    "static-params-section = static_params\n",
    "dist-section prior =\n",
    "force =\n",
    "\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";   Inference\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "[inference]\n",
    "verbose =\n",
    "seed = 12\n",
    "config-files = inference.ini data.ini sampler.ini\n",
    "output-file = inference.hdf\n",
    "nprocesses = 10\n",
    "force =\n",
    "\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";   Visualize\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "[plot]\n",
    "input-file = inference.hdf\n",
    "output-file = plots/posteriors.png\n",
    "plot-scatter =\n",
    "plot-marginal =\n",
    "plot-prior = inference.ini data.ini\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[static_params]\n",
      "tc = 1126259462.420\n",
      ";mass1 = 37\n",
      "mass2 = 32\n",
      "ra = 2.2\n",
      "dec = -1.25\n",
      "inclination = 2.5\n",
      "coa_phase = 1.5\n",
      "polarization = 1.75\n",
      "distance = 100\n",
      "f_ref = 20\n",
      "f_lower = 18\n",
      "approximant = ENIGMA\n",
      "taper = start\n",
      "\n",
      "[variable_params]\n",
      "mass1 =\n",
      "eccentricity =\n",
      "mean_per_ano =\n",
      "\n",
      "[prior-mass1]\n",
      "name = uniform\n",
      "min-mass1 = 10.\n",
      "max-mass1 = 80.\n",
      "\n",
      "[prior-eccentricity]\n",
      "name = uniform\n",
      "min-eccentricity = 0.\n",
      "max-eccentricity = 0.2\n",
      "\n",
      "[prior-mean_per_ano]\n",
      "name = uniform\n",
      "min-mean_per_ano = 0.\n",
      "max-mean_per_ano = 3.1416\n",
      "[data]\n",
      "instruments = H1 L1\n",
      "trigger-time = 1126259462.42\n",
      "analysis-start-time = -6\n",
      "analysis-end-time = 2\n",
      "; strain settings\n",
      "sample-rate = 2048\n",
      "fake-strain = H1:aLIGOaLIGODesignSensitivityT1800044 L1:aLIGOaLIGODesignSensitivityT1800044\n",
      "fake-strain-seed = H1:44 L1:45\n",
      "; psd settings\n",
      "psd-estimation = median-mean\n",
      "psd-inverse-length = 8\n",
      "psd-segment-length = 8\n",
      "psd-segment-stride = 4\n",
      "psd-start-time = -256\n",
      "psd-end-time = 256\n",
      "; even though we're making fake strain, the strain\n",
      "; module requires a channel to be provided, so we'll\n",
      "; just make one up\n",
      "channel-name = H1:STRAIN L1:STRAIN\n",
      "; Providing an injection file will cause a simulated\n",
      "; signal to be added to the data\n",
      "injection-file = injection.hdf\n",
      "; We'll use a high-pass filter so as not to get numerical errors from the large\n",
      "; amplitude low frequency noise. Here we use 15 Hz, which is safely below the\n",
      "; low frequency cutoff of our likelihood integral (20 Hz)\n",
      "strain-high-pass = 15\n",
      "; The pad-data argument is for the high-pass filter: 8s are added to the\n",
      "; beginning/end of the analysis/psd times when the data is loaded. After the\n",
      "; high pass filter is applied, the additional time is discarded. This pad is\n",
      "; *in addition to* the time added to the analysis start/end time for the PSD\n",
      "; inverse length. Since it is discarded before the data is transformed for the\n",
      "; likelihood integral, it has little affect on the run time.\n",
      "pad-data = 8\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      ";      SAMPLER\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "[sampler]\n",
      "name = emcee_pt\n",
      "nwalkers = 200\n",
      "ntemps = 20\n",
      "effective-nsamples = 1000\n",
      "checkpoint-interval = 2000\n",
      "max-samples-per-chain = 1000\n",
      "\n",
      "[sampler-burn_in]\n",
      "burn-in-test = nacl & max_posterior\n",
      "\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      ";   Sampling transforms\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "[sampling_params]\n",
      "; parameters on the left will be sampled in\n",
      "; parametes on the right\n",
      "mass1, mass2 : mchirp, q\n",
      "\n",
      "[sampling_transforms-mchirp+q]\n",
      "; inputs mass1, mass2\n",
      "; outputs mchirp, q\n",
      "name = mass1_mass2_to_mchirp_q\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      ";   Model\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "[model]\n",
      "name = gaussian_noise\n",
      "low-frequency-cutoff = 20.0\n",
      "\n",
      "\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      ";   Sampling parameters\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "[variable_params]\n",
      "; waveform parameters that will vary in MCMC\n",
      "delta_tc =\n",
      "mass1 =\n",
      "mass2 =\n",
      "spin1_a =\n",
      "spin1_azimuthal =\n",
      "spin1_polar =\n",
      "spin2_a =\n",
      "spin2_azimuthal =\n",
      "spin2_polar =\n",
      "distance =\n",
      "coa_phase =\n",
      "inclination =\n",
      "polarization =\n",
      "ra =\n",
      "dec =\n",
      "\n",
      "[static_params]\n",
      "; waveform parameters that will not change in MCMC\n",
      "approximant = IMRPhenomPv2\n",
      "f_lower = 20\n",
      "f_ref = 20\n",
      "; we'll set the tc by using the trigger time in the data\n",
      "; section of the config file + delta_tc\n",
      "trigger_time = ${data|trigger-time}\n",
      "\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      ";   Sampling priors\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "[prior-delta_tc]\n",
      "; coalescence time prior\n",
      "name = uniform\n",
      "min-delta_tc = -0.1\n",
      "max-delta_tc = 0.1\n",
      "\n",
      "[waveform_transforms-tc]\n",
      "; we need to provide tc to the waveform generator\n",
      "name = custom\n",
      "inputs = delta_tc\n",
      "tc = ${data|trigger-time} + delta_tc\n",
      "\n",
      "[prior-mass1]\n",
      "name = uniform\n",
      "min-mass1 = 10.\n",
      "max-mass1 = 80.\n",
      "\n",
      "[prior-mass2]\n",
      "name = uniform\n",
      "min-mass2 = 10.\n",
      "max-mass2 = 80.\n",
      "\n",
      "[prior-spin1_a]\n",
      "name = uniform\n",
      "min-spin1_a = 0.0\n",
      "max-spin1_a = 0.99\n",
      "\n",
      "[prior-spin1_polar+spin1_azimuthal]\n",
      "name = uniform_solidangle\n",
      "polar-angle = spin1_polar\n",
      "azimuthal-angle = spin1_azimuthal\n",
      "\n",
      "[prior-spin2_a]\n",
      "name = uniform\n",
      "min-spin2_a = 0.0\n",
      "max-spin2_a = 0.99\n",
      "\n",
      "[prior-spin2_polar+spin2_azimuthal]\n",
      "name = uniform_solidangle\n",
      "polar-angle = spin2_polar\n",
      "azimuthal-angle = spin2_azimuthal\n",
      "\n",
      "[prior-distance]\n",
      "; following gives a uniform volume prior\n",
      "name = uniform_radius\n",
      "min-distance = 10\n",
      "max-distance = 1000\n",
      "\n",
      "[prior-coa_phase]\n",
      "; coalescence phase prior\n",
      "name = uniform_angle\n",
      "\n",
      "[prior-inclination]\n",
      "; inclination prior\n",
      "name = sin_angle\n",
      "\n",
      "[prior-ra+dec]\n",
      "; sky position prior\n",
      "name = uniform_sky\n",
      "\n",
      "[prior-polarization]\n",
      "; polarization prior\n",
      "name = uniform_angle\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      ";   Executables\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "[executables]\n",
      "inspinj = ${which:pycbc_create_injections}\n",
      "inference = ${which:pycbc_inference}\n",
      "\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      ";   Workflow\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "[workflow]\n",
      "accounting-group = ligo.dev.o3.cbc.explore.test\n",
      "templates-per-job = 100\n",
      "log-path = /usr/prayush/\n",
      "bank-file = /home/prayush.kumar/projects/template_banks/testing_banksim/bank.xml\n",
      "injections-per-job = 10\n",
      "templates-per-job = 10000\n",
      "banksim-request-memory = 8G\n",
      "data = data.ini\n",
      "sampler = sampler.ini,sampler.ini\n",
      "inference = inference.ini\n",
      "\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      ";   Injections\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "[inspinj]\n",
      "config = injection.ini\n",
      "ninjections = 10\n",
      "seed = 10\n",
      "output-file = injection.hdf\n",
      "variable-params-section = variable_params\n",
      "static-params-section = static_params\n",
      "dist-section prior =\n",
      "force =\n"
     ]
    }
   ],
   "source": [
    "!cat injection.ini\n",
    "!cat data.ini\n",
    "!cat sampler.ini\n",
    "!cat inference.ini\n",
    "!cat config.ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not import ligolw in /home/prayush/src/GWNRTools/GWNRTools/Stats/FisherMatrixUtilities.pyc, LIGO XML tables wont be read\n",
      "usage: /home/prayush/src/GWNRTools/bin/gwnrtools_create_injection_inference_workflow [--options]\n",
      "\n",
      "Setup workflow to perferm Bayesian parameter estimation runs on a custom set\n",
      "of simulated signals\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --version             Prints version information.\n",
      "  --verbose             Print logging messages.\n",
      "  --skip-creating-injections\n",
      "                        Skip calling lalapps_inspinj and assume injections\n",
      "                        already exist\n",
      "  --output-file OUTPUT_FILE\n",
      "                        Output file path.\n",
      "  --force               If the output-file already exists, overwrite it.\n",
      "                        Otherwise, an OSError is raised.\n",
      "  --save-backup         Don't delete the backup file after the run has\n",
      "                        completed.\n",
      "  --nprocesses NPROCESSES\n",
      "                        Number of processes to use. If not given then only a\n",
      "                        single core will be used.\n",
      "  --use-mpi             Use MPI to parallelize the sampler\n",
      "  --samples-file SAMPLES_FILE\n",
      "                        Use an iteration from an InferenceFile as the initial\n",
      "                        proposal distribution. The same number of walkers and\n",
      "                        the same [variable_params] section in the\n",
      "                        configuration file should be used. The priors must\n",
      "                        allow encompass the initial positions from the\n",
      "                        InferenceFile being read.\n",
      "  --seed SEED           Seed to use for the random number generator that\n",
      "                        initially distributes the walkers. Default is 0.\n",
      "\n",
      "Configuration:\n",
      "  Options needed for parsing config file(s).\n",
      "\n",
      "  --config-files CONFIGFILE [CONFIGFILE ...]\n",
      "                        List of config files to be used in analysis.\n",
      "  --config-overrides [SECTION:OPTION:VALUE [SECTION:OPTION:VALUE ...]]\n",
      "                        List of section,option,value combinations to add into\n",
      "                        the configuration file. Normally the gps start and end\n",
      "                        times might be provided this way, and user specific\n",
      "                        locations (ie. output directories). This can also be\n",
      "                        provided as SECTION:OPTION or SECTION:OPTION: both of\n",
      "                        which indicate that the corresponding value is left\n",
      "                        blank.\n",
      "  --config-delete [SECTION:OPTION [SECTION:OPTION ...]]\n",
      "                        List of section,option combinations to delete from the\n",
      "                        configuration file. This can also be provided as\n",
      "                        SECTION which deletes the enture section from the\n",
      "                        configuration file or SECTION:OPTION which deletes a\n",
      "                        specific option from a given section.\n",
      "\n",
      "Options for selecting the FFT backend and controlling its performance in this program.:\n",
      "  --fft-backends [FFT_BACKENDS [FFT_BACKENDS ...]]\n",
      "                        Preference list of the FFT backends. Choices are:\n",
      "                        ['fftw', 'numpy']\n",
      "  --fftw-measure-level FFTW_MEASURE_LEVEL\n",
      "                        Determines the measure level used in planning FFTW\n",
      "                        FFTs; allowed values are: [0, 1, 2, 3]\n",
      "  --fftw-threads-backend FFTW_THREADS_BACKEND\n",
      "                        Give 'openmp', 'pthreads' or 'unthreaded' to specify\n",
      "                        which threaded FFTW to use\n",
      "  --fftw-input-float-wisdom-file FFTW_INPUT_FLOAT_WISDOM_FILE\n",
      "                        Filename from which to read single-precision wisdom\n",
      "  --fftw-input-double-wisdom-file FFTW_INPUT_DOUBLE_WISDOM_FILE\n",
      "                        Filename from which to read double-precision wisdom\n",
      "  --fftw-output-float-wisdom-file FFTW_OUTPUT_FLOAT_WISDOM_FILE\n",
      "                        Filename to which to write single-precision wisdom\n",
      "  --fftw-output-double-wisdom-file FFTW_OUTPUT_DOUBLE_WISDOM_FILE\n",
      "                        Filename to which to write double-precision wisdom\n",
      "  --fftw-import-system-wisdom\n",
      "                        If given, call fftw[f]_import_system_wisdom()\n",
      "\n",
      "Options for selecting optimization-specific settings:\n",
      "  --cpu-affinity CPU_AFFINITY\n",
      "                        A set of CPUs on which to run, specified in a format\n",
      "                        suitable to pass to taskset.\n",
      "  --cpu-affinity-from-env CPU_AFFINITY_FROM_ENV\n",
      "                        The name of an enivornment variable containing a set\n",
      "                        of CPUs on which to run, specified in a format\n",
      "                        suitable to pass to taskset.\n",
      "\n",
      "Options for selecting the processing scheme in this program.:\n",
      "  --processing-scheme PROCESSING_SCHEME\n",
      "                        The choice of processing scheme. Choices are ['mkl',\n",
      "                        'numpy', 'cuda', 'cpu']. (optional for CPU scheme) The\n",
      "                        number of execution threads can be indicated by\n",
      "                        cpu:NUM_THREADS, where NUM_THREADS is an integer. The\n",
      "                        default is a single thread. If the scheme is provided\n",
      "                        as cpu:env, the number of threads can be provided by\n",
      "                        the PYCBC_NUM_THREADS environment variable. If the\n",
      "                        environment variable is not set, the number of threads\n",
      "                        matches the number of logical cores.\n",
      "  --processing-device-id PROCESSING_DEVICE_ID\n",
      "                        (optional) ID of GPU to use for accelerated processing\n"
     ]
    }
   ],
   "source": [
    "!/home/prayush/src/GWNRTools/bin/gwnrtools_create_injection_inference_workflow -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prayush/local/venv/pycbc_inf/bin/pycbc_create_injections\r\n"
     ]
    }
   ],
   "source": [
    "!which pycbc_create_injections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not import ligolw in /home/prayush/src/GWNRTools/GWNRTools/Stats/FisherMatrixUtilities.pyc, LIGO XML tables wont be read\n",
      "2020-02-25 11:43:26,023 Using seed 0\n",
      "2020-02-25 11:43:26,024 Will setup analyses in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,024 Running with CPU support: 1 threads\n",
      "2020-02-25 11:43:26,120 Reading configuration file\n",
      "2020-02-25 11:43:26,121 Making workspace directories\n",
      "2020-02-25 11:43:26,144 Creating DAG\n",
      "('config options: ', <pycbc.workflow.configuration.WorkflowConfigParser instance at 0x7f4e7f1e6488>)\n",
      "2020-02-25 11:43:26,144 Making injection000/data/sampler2/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,180 Copying config files to injection000/data/sampler2/inference\n",
      "2020-02-25 11:43:26,180 Copying executables to injection000/data/sampler2/inference/scripts/\n",
      "2020-02-25 11:43:26,184 Making injection001/data/sampler2/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,217 Copying config files to injection001/data/sampler2/inference\n",
      "2020-02-25 11:43:26,218 Copying executables to injection001/data/sampler2/inference/scripts/\n",
      "2020-02-25 11:43:26,220 Making injection004/data/sampler2/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,255 Copying config files to injection004/data/sampler2/inference\n",
      "2020-02-25 11:43:26,256 Copying executables to injection004/data/sampler2/inference/scripts/\n",
      "2020-02-25 11:43:26,257 Making injection007/data/sampler/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,294 Copying config files to injection007/data/sampler/inference\n",
      "2020-02-25 11:43:26,294 Copying executables to injection007/data/sampler/inference/scripts/\n",
      "2020-02-25 11:43:26,295 Making injection006/data/sampler/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,329 Copying config files to injection006/data/sampler/inference\n",
      "2020-02-25 11:43:26,330 Copying executables to injection006/data/sampler/inference/scripts/\n",
      "2020-02-25 11:43:26,331 Making injection005/data/sampler/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,371 Copying config files to injection005/data/sampler/inference\n",
      "2020-02-25 11:43:26,372 Copying executables to injection005/data/sampler/inference/scripts/\n",
      "2020-02-25 11:43:26,373 Making injection007/data/sampler2/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,410 Copying config files to injection007/data/sampler2/inference\n",
      "2020-02-25 11:43:26,411 Copying executables to injection007/data/sampler2/inference/scripts/\n",
      "2020-02-25 11:43:26,412 Making injection006/data/sampler2/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,447 Copying config files to injection006/data/sampler2/inference\n",
      "2020-02-25 11:43:26,447 Copying executables to injection006/data/sampler2/inference/scripts/\n",
      "2020-02-25 11:43:26,449 Making injection002/data/sampler/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,484 Copying config files to injection002/data/sampler/inference\n",
      "2020-02-25 11:43:26,485 Copying executables to injection002/data/sampler/inference/scripts/\n",
      "2020-02-25 11:43:26,486 Making injection000/data/sampler/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,525 Copying config files to injection000/data/sampler/inference\n",
      "2020-02-25 11:43:26,525 Copying executables to injection000/data/sampler/inference/scripts/\n",
      "2020-02-25 11:43:26,526 Making injection001/data/sampler/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,567 Copying config files to injection001/data/sampler/inference\n",
      "2020-02-25 11:43:26,567 Copying executables to injection001/data/sampler/inference/scripts/\n",
      "2020-02-25 11:43:26,569 Making injection008/data/sampler/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,609 Copying config files to injection008/data/sampler/inference\n",
      "2020-02-25 11:43:26,610 Copying executables to injection008/data/sampler/inference/scripts/\n",
      "2020-02-25 11:43:26,611 Making injection004/data/sampler/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,642 Copying config files to injection004/data/sampler/inference\n",
      "2020-02-25 11:43:26,643 Copying executables to injection004/data/sampler/inference/scripts/\n",
      "2020-02-25 11:43:26,644 Making injection003/data/sampler2/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,682 Copying config files to injection003/data/sampler2/inference\n",
      "2020-02-25 11:43:26,683 Copying executables to injection003/data/sampler2/inference/scripts/\n",
      "2020-02-25 11:43:26,684 Making injection009/data/sampler/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,721 Copying config files to injection009/data/sampler/inference\n",
      "2020-02-25 11:43:26,722 Copying executables to injection009/data/sampler/inference/scripts/\n",
      "2020-02-25 11:43:26,724 Making injection005/data/sampler2/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,764 Copying config files to injection005/data/sampler2/inference\n",
      "2020-02-25 11:43:26,765 Copying executables to injection005/data/sampler2/inference/scripts/\n",
      "2020-02-25 11:43:26,766 Making injection008/data/sampler2/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,800 Copying config files to injection008/data/sampler2/inference\n",
      "2020-02-25 11:43:26,800 Copying executables to injection008/data/sampler2/inference/scripts/\n",
      "2020-02-25 11:43:26,801 Making injection009/data/sampler2/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,842 Copying config files to injection009/data/sampler2/inference\n",
      "2020-02-25 11:43:26,843 Copying executables to injection009/data/sampler2/inference/scripts/\n",
      "2020-02-25 11:43:26,844 Making injection002/data/sampler2/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,880 Copying config files to injection002/data/sampler2/inference\n",
      "2020-02-25 11:43:26,881 Copying executables to injection002/data/sampler2/inference/scripts/\n",
      "2020-02-25 11:43:26,882 Making injection003/data/sampler/inference in /home/prayush/research/test_pycbc_inf2\n",
      "2020-02-25 11:43:26,920 Copying config files to injection003/data/sampler/inference\n",
      "2020-02-25 11:43:26,921 Copying executables to injection003/data/sampler/inference/scripts/\n",
      "/home/prayush/local/venv/pycbc_inf/bin/pycbc_create_injections\n",
      "/home/prayush/local/venv/pycbc_inf/bin/pycbc_inference\n",
      "2020-02-25 11:43:26,924 Done\n"
     ]
    }
   ],
   "source": [
    "!/home/prayush/src/GWNRTools/bin/gwnrtools_create_injection_inference_workflow --verbose\\\n",
    "    --config-file=config.ini --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/prayush/research/test_pycbc_inf2/injection000/data/sampler/inference'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(os.path.abspath('injection000/data/sampler/inference/make_injection'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def populate(options, k):\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    if k == 0: return [[]]\n",
    "    \n",
    "    for i, first_elem in enumerate(options, 1):\n",
    "        \n",
    "        #first_elem = options[i]\n",
    "        \n",
    "        #reduced_options = copy.deepcopy(options)\n",
    "        #reduced_options.pop(i)\n",
    "        reduced_options = options[i:]\n",
    "                \n",
    "        last_k_minus_1_elems = populate(reduced_options, k - 1)\n",
    "        \n",
    "        for j in range(len(last_k_minus_1_elems)):\n",
    "            li = last_k_minus_1_elems[j]\n",
    "            li.extend([first_elem])\n",
    "        \n",
    "        print(last_k_minus_1_elems)\n",
    "        \n",
    "        output.extend(last_k_minus_1_elems)\n",
    "            \n",
    "    return output\n",
    "\n",
    "def combinations(sequence, length, NULL = object()):\n",
    "    if length <= 0:\n",
    "        combos = [NULL]\n",
    "    else:\n",
    "        combos = []\n",
    "        for i, item in enumerate(sequence, 1):\n",
    "            rem_items = sequence[i:]\n",
    "            rem_combos = combinations(rem_items, length - 1)\n",
    "            \n",
    "            print([item if combo is NULL else [item, combo] for combo in rem_combos])\n",
    "            \n",
    "            combos.extend(item if combo is NULL else [item, combo] for combo in rem_combos)\n",
    "    return combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2]]\n",
      "[[3]]\n",
      "[[4]]\n",
      "[[2, 1], [3, 1], [4, 1]]\n",
      "[[3]]\n",
      "[[4]]\n",
      "[[3, 2], [4, 2]]\n",
      "[[4]]\n",
      "[[4, 3]]\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[2, 1], [3, 1], [4, 1], [3, 2], [4, 2], [4, 3]]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "populate([1,2,3,4], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[[1, 2], [1, 3], [1, 4]]\n",
      "[3]\n",
      "[4]\n",
      "[[2, 3], [2, 4]]\n",
      "[4]\n",
      "[[3, 4]]\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 2], [1, 3], [1, 4], [2, 3], [2, 4], [3, 4]]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations([1,2,3,4], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'SEOBNRv4' in td_approximants()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# DATA.INI\n",
    "with open(\"data.ini\", \"w\") as fout:\n",
    "    fout.write(\"\"\"\\\n",
    "[data]\n",
    "instruments = H1 L1\n",
    "trigger-time = 1126259462.42\n",
    "analysis-start-time = -6\n",
    "analysis-end-time = 2\n",
    "; strain settings\n",
    "sample-rate = 2048\n",
    "fake-strain = H1:aLIGOaLIGODesignSensitivityT1800044 L1:aLIGOaLIGODesignSensitivityT1800044\n",
    "fake-strain-seed = H1:44 L1:45\n",
    "; psd settings\n",
    "psd-estimation = median-mean\n",
    "psd-inverse-length = 8\n",
    "psd-segment-length = 8\n",
    "psd-segment-stride = 4\n",
    "psd-start-time = -256\n",
    "psd-end-time = 256\n",
    "; even though we're making fake strain, the strain\n",
    "; module requires a channel to be provided, so we'll\n",
    "; just make one up\n",
    "channel-name = H1:STRAIN L1:STRAIN\n",
    "; Providing an injection file will cause a simulated\n",
    "; signal to be added to the data\n",
    "injection-file = injection.hdf\n",
    "; We'll use a high-pass filter so as not to get numerical errors from the large\n",
    "; amplitude low frequency noise. Here we use 15 Hz, which is safely below the\n",
    "; low frequency cutoff of our likelihood integral (20 Hz)\n",
    "strain-high-pass = 15\n",
    "; The pad-data argument is for the high-pass filter: 8s are added to the\n",
    "; beginning/end of the analysis/psd times when the data is loaded. After the\n",
    "; high pass filter is applied, the additional time is discarded. This pad is\n",
    "; *in addition to* the time added to the analysis start/end time for the PSD\n",
    "; inverse length. Since it is discarded before the data is transformed for the\n",
    "; likelihood integral, it has little affect on the run time.\n",
    "pad-data = 8\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data.ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# emcee_pt-gw150914_like\n",
    "with open(\"emcee_pt-gw150914_like.ini\", \"w\") as fout:\n",
    "    fout.write(\"\"\"\\\n",
    "[sampler]\n",
    "name = emcee_pt\n",
    "nwalkers = 200\n",
    "ntemps = 20\n",
    "effective-nsamples = 1000\n",
    "checkpoint-interval = 2000\n",
    "max-samples-per-chain = 1000\n",
    "\n",
    "[sampler-burn_in]\n",
    "burn-in-test = nacl & max_posterior\n",
    "\n",
    ";\n",
    ";   Sampling transforms\n",
    ";\n",
    "[sampling_params]\n",
    "; parameters on the left will be sampled in\n",
    "; parametes on the right\n",
    "mass1, mass2 : mchirp, q\n",
    "\n",
    "[sampling_transforms-mchirp+q]\n",
    "; inputs mass1, mass2\n",
    "; outputs mchirp, q\n",
    "name = mass1_mass2_to_mchirp_q\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat emcee_pt-gw150914_like.ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# gw150914_like\n",
    "with open(\"gw150914_like.ini\", \"w\") as fout:\n",
    "    fout.write(\"\"\"\\\n",
    "[model]\n",
    "name = gaussian_noise\n",
    "low-frequency-cutoff = 20.0\n",
    "\n",
    "[variable_params]\n",
    "; waveform parameters that will vary in MCMC\n",
    "delta_tc =\n",
    "mass1 =\n",
    "mass2 =\n",
    "spin1_a =\n",
    "spin1_azimuthal =\n",
    "spin1_polar =\n",
    "spin2_a =\n",
    "spin2_azimuthal =\n",
    "spin2_polar =\n",
    "distance =\n",
    "coa_phase =\n",
    "inclination =\n",
    "polarization =\n",
    "ra =\n",
    "dec =\n",
    "\n",
    "[static_params]\n",
    "; waveform parameters that will not change in MCMC\n",
    "approximant = ENIGMA\n",
    "f_lower = 20\n",
    "f_ref = 20\n",
    "; we'll set the tc by using the trigger time in the data\n",
    "; section of the config file + delta_tc\n",
    "trigger_time = ${data|trigger-time}\n",
    "\n",
    "[prior-delta_tc]\n",
    "; coalescence time prior\n",
    "name = uniform\n",
    "min-delta_tc = -0.1\n",
    "max-delta_tc = 0.1\n",
    "\n",
    "[waveform_transforms-tc]\n",
    "; we need to provide tc to the waveform generator\n",
    "name = custom\n",
    "inputs = delta_tc\n",
    "tc = ${data|trigger-time} + delta_tc\n",
    "\n",
    "[prior-mass1]\n",
    "name = uniform\n",
    "min-mass1 = 10.\n",
    "max-mass1 = 80.\n",
    "\n",
    "[prior-mass2]\n",
    "name = uniform\n",
    "min-mass2 = 10.\n",
    "max-mass2 = 80.\n",
    "\n",
    "[prior-spin1_a]\n",
    "name = uniform\n",
    "min-spin1_a = 0.0\n",
    "max-spin1_a = 0.99\n",
    "\n",
    "[prior-spin1_polar+spin1_azimuthal]\n",
    "name = uniform_solidangle\n",
    "polar-angle = spin1_polar\n",
    "azimuthal-angle = spin1_azimuthal\n",
    "\n",
    "[prior-spin2_a]\n",
    "name = uniform\n",
    "min-spin2_a = 0.0\n",
    "max-spin2_a = 0.99\n",
    "\n",
    "[prior-spin2_polar+spin2_azimuthal]\n",
    "name = uniform_solidangle\n",
    "polar-angle = spin2_polar\n",
    "azimuthal-angle = spin2_azimuthal\n",
    "\n",
    "[prior-distance]\n",
    "; following gives a uniform volume prior\n",
    "name = uniform_radius\n",
    "min-distance = 10\n",
    "max-distance = 1000\n",
    "\n",
    "[prior-coa_phase]\n",
    "; coalescence phase prior\n",
    "name = uniform_angle\n",
    "\n",
    "[prior-inclination]\n",
    "; inclination prior\n",
    "name = sin_angle\n",
    "\n",
    "[prior-ra+dec]\n",
    "; sky position prior\n",
    "name = uniform_sky\n",
    "\n",
    "[prior-polarization]\n",
    "; polarization prior\n",
    "name = uniform_angle\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!cat gw150914_like.ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# RUN.SH\n",
    "with open(\"run.sh\", \"w\") as fout:\n",
    "    fout.write(\"\"\"#!/bin/sh\n",
    "\n",
    "# sampler parameters\n",
    "PRIOR_CONFIG=gw150914_like.ini\n",
    "DATA_CONFIG=data.ini\n",
    "SAMPLER_CONFIG=emcee_pt-gw150914_like.ini\n",
    "OUTPUT_PATH=inference.hdf\n",
    "\n",
    "# the following sets the number of cores to use; adjust as needed to\n",
    "# your computer's capabilities\n",
    "NPROCS=10\n",
    "\n",
    "# run sampler\n",
    "# Running with OMP_NUM_THREADS=1 stops lalsimulation\n",
    "# from spawning multiple jobs that would otherwise be used\n",
    "# by pycbc_inference and cause a reduced runtime.\n",
    "OMP_NUM_THREADS=1 \\\n",
    "pycbc_inference --verbose \\\n",
    "    --seed 12 \\\n",
    "    --config-file ${PRIOR_CONFIG} ${DATA_CONFIG} ${SAMPLER_CONFIG} \\\n",
    "    --output-file ${OUTPUT_PATH} \\\n",
    "    --nprocesses ${NPROCS} \\\n",
    "    --force\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat run.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
