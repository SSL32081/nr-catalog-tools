{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and run Bayesian inference on a batch of GW events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prayush/local/venv/pycbc_inf/local/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['rc']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import h5py\n",
    "import subprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('text', usetex = True)\n",
    "\n",
    "plt.rcParams.update(  # try to match font sizes of document\n",
    "  {'axes.labelsize': 20,\n",
    "   'axes.titlesize': 20,\n",
    "   'legend.fontsize': 20,\n",
    "   'xtick.labelsize': 20,\n",
    "   'ytick.labelsize': 20,\n",
    "   'text.usetex': True,\n",
    "   'font.family': 'serif',\n",
    "   'font.serif': ['palatino'],\n",
    "   'savefig.dpi': 300\n",
    "   })\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "import GWNRTools\n",
    "\n",
    "#sys.path.append('/home/prayush.kumar/src/GWNRTools/bin/')\n",
    "#sys.path.append('/home/prayush/src/GWNRTools/bin/')\n",
    "#sys.path.append('/home/prayush.kumar/local/venv/pycbc_master_enigma/src/GWNRTools/bin/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = '/home/prayush/research/test_pycbc_gw150914'\n",
    "try: os.makedirs(run_dir)\n",
    "except: pass\n",
    "os.chdir(run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prayush/research/test_pycbc_gw150914\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbh_precessing.ini  config.ini\temcee_pt.ini  log\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Generate sampler / inference config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: /home/prayush/src/GWNRTools/bin//gwnrtools_write_inference_configs [--options]\r\n",
      "\r\n",
      "Get and write configuration files for generating a workflow to perform\r\n",
      "Bayesian parameter estimation runs on a custom set of simulated signals\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --version             Prints version information.\r\n",
      "  --verbose             Print logging messages.\r\n",
      "  --write-data-config WRITE_DATA_CONFIG\r\n",
      "                        Write data config files and exit.\r\n",
      "  --write-sampler-config WRITE_SAMPLER_CONFIG\r\n",
      "                        Write sampler config files and exit.\r\n",
      "  --write-inference-config WRITE_INFERENCE_CONFIG\r\n",
      "                        Write inference config files and exit.\r\n",
      "  --n-cpus N_CPUS\r\n",
      "  --checkpoint-interval CHECKPOINT_INTERVAL\r\n",
      "  --n-live N_LIVE\r\n",
      "  --n-maxmcmc N_MAXMCMC\r\n",
      "  --dlogz DLOGZ\r\n",
      "  --n-walkers N_WALKERS\r\n",
      "  --n-temperatures N_TEMPERATURES\r\n",
      "  --n-maxsamps-per-walker N_MAXSAMPS_PER_WALKER\r\n",
      "  --n-eff-samples N_EFF_SAMPLES\r\n",
      "  --show-available-configs\r\n",
      "                        Show available options for all configurations.\r\n",
      "  --output-dir OUTPUT_DIR\r\n",
      "                        Output directory path.\r\n"
     ]
    }
   ],
   "source": [
    "!gwnrtools_write_inference_configs -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference: ['bbh_precessing']\r\n",
      "data: [u'GW151012', u'GW170608', u'GW170729', u'GW170817', u'GW170818', u'GW170814', u'GW150914', u'GW170104', u'GW170809', u'GW151226', u'GW170823']\r\n",
      "sampler: ['epsie', 'dynesty', 'multinest', 'emcee_pt', 'ultranest', 'emcee', 'cpnest']\r\n"
     ]
    }
   ],
   "source": [
    "!gwnrtools_write_inference_configs --show-available-configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-17 15:41:12,043 Writing config file for sampler settings..\r\n",
      "2020-03-17 15:41:12,043 Writing config file for inference settings..\r\n",
      "2020-03-17 15:41:12,043 Done\r\n"
     ]
    }
   ],
   "source": [
    "!gwnrtools_write_inference_configs --verbose\\\n",
    "  --write-sampler-config emcee_pt --write-inference-config bbh_precessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbh_precessing.ini  emcee_pt.ini\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sampler]\r\n",
      "name = emcee_pt\r\n",
      "nprocesses = 10\r\n",
      "nwalkers = 1000\r\n",
      "ntemps = 20\r\n",
      "effective-nsamples = 4000\r\n",
      "max-samples-per-chain = 1000\r\n",
      "checkpoint-interval = 2000\r\n",
      "\r\n",
      "[sampler-burn_in]\r\n",
      "burn-in-test = nacl & max_posterior\r\n",
      "\r\n",
      ";\r\n",
      ";   Sampling transforms\r\n",
      ";\r\n",
      "[sampling_params]\r\n",
      "; parameters on the left will be sampled in\r\n",
      "; parametes on the right\r\n",
      "mass1, mass2 : mchirp, q\r\n",
      "\r\n",
      "[sampling_transforms-mchirp+q]\r\n",
      "; inputs mass1, mass2\r\n",
      "; outputs mchirp, q\r\n",
      "name = mass1_mass2_to_mchirp_q\r\n",
      "[model]\r\n",
      "name = gaussian_noise\r\n",
      "low-frequency-cutoff = 20.0\r\n",
      "\r\n",
      "[variable_params]\r\n",
      "; waveform parameters that will vary in MCMC\r\n",
      "delta_tc =\r\n",
      "mass1 =\r\n",
      "mass2 =\r\n",
      "spin1_a =\r\n",
      "spin1_azimuthal =\r\n",
      "spin1_polar =\r\n",
      "spin2_a =\r\n",
      "spin2_azimuthal =\r\n",
      "spin2_polar =\r\n",
      "distance =\r\n",
      "coa_phase =\r\n",
      "inclination =\r\n",
      "polarization =\r\n",
      "ra =\r\n",
      "dec =\r\n",
      "\r\n",
      "[static_params]\r\n",
      "; waveform parameters that will not change in MCMC\r\n",
      "approximant = IMRPhenomPv2\r\n",
      "f_lower = 20\r\n",
      "f_ref = 20\r\n",
      "; we'll set the tc by using the trigger time in the data\r\n",
      "; section of the config file + delta_tc\r\n",
      "trigger_time = ${data|trigger-time}\r\n",
      "\r\n",
      "[prior-delta_tc]\r\n",
      "; coalescence time prior\r\n",
      "name = uniform\r\n",
      "min-delta_tc = -0.1\r\n",
      "max-delta_tc = 0.1\r\n",
      "\r\n",
      "[waveform_transforms-tc]\r\n",
      "; we need to provide tc to the waveform generator\r\n",
      "name = custom\r\n",
      "inputs = delta_tc\r\n",
      "tc = ${data|trigger-time} + delta_tc\r\n",
      "\r\n",
      ";Mass1 of GW151012 $\\in$ [28.7, 38.1]\r\n",
      ";Mass1 of GW170608 $\\in$ [12.7, 16.5]\r\n",
      ";Mass1 of GW170729 $\\in$ [60.4, 66.4]\r\n",
      ";Mass1 of GW150914 $\\in$ [38.7, 40.3]\r\n",
      ";Mass1 of GW151226 $\\in$ [16.9, 22.5]\r\n",
      ";Mass1 of GW170814 $\\in$ [33.6, 36.2]\r\n",
      ";Mass1 of GW170817 $\\in$ [1.56, 1.58]\r\n",
      ";Mass1 of GW170104 $\\in$ [36.4, 38.1]\r\n",
      ";Mass1 of GW170809 $\\in$ [40.9, 43.3]\r\n",
      ";Mass1 of GW170818 $\\in$ [40.1, 42.9]\r\n",
      ";Mass1 of GW170823 $\\in$ [46.2, 50.7]\r\n",
      "\r\n",
      "[prior-mass1]\r\n",
      "name = uniform\r\n",
      "min-mass1 = 10.\r\n",
      "max-mass1 = 80.\r\n",
      "\r\n",
      ";Mass2 of GW151012 $\\in$ [18.4, 17.7]\r\n",
      ";Mass2 of GW170608 $\\in$ [9.8, 9.0]\r\n",
      ";Mass2 of GW170729 $\\in$ [44.1, 43.1]\r\n",
      ";Mass2 of GW150914 $\\in$ [35.0, 33.6]\r\n",
      ";Mass2 of GW151226 $\\in$ [10.2, 9.9]\r\n",
      ";Mass2 of GW170814 $\\in$ [29.2, 28.0]\r\n",
      ";Mass2 of GW170817 $\\in$ [1.36, 1.36]\r\n",
      ";Mass2 of GW170104 $\\in$ [24.6, 24.9]\r\n",
      ";Mass2 of GW170809 $\\in$ [29.0, 28.9]\r\n",
      ";Mass2 of GW170818 $\\in$ [31.9, 31.0]\r\n",
      ";Mass2 of GW170823 $\\in$ [36.8, 35.7]\r\n",
      "\r\n",
      "[prior-mass2]\r\n",
      "name = uniform\r\n",
      "min-mass2 = 10.\r\n",
      "max-mass2 = 80.\r\n",
      "\r\n",
      "[prior-spin1_a]\r\n",
      "name = uniform\r\n",
      "min-spin1_a = 0.0\r\n",
      "max-spin1_a = 0.99\r\n",
      "\r\n",
      "[prior-spin1_polar+spin1_azimuthal]\r\n",
      "name = uniform_solidangle\r\n",
      "polar-angle = spin1_polar\r\n",
      "azimuthal-angle = spin1_azimuthal\r\n",
      "\r\n",
      "[prior-spin2_a]\r\n",
      "name = uniform\r\n",
      "min-spin2_a = 0.0\r\n",
      "max-spin2_a = 0.99\r\n",
      "\r\n",
      "[prior-spin2_polar+spin2_azimuthal]\r\n",
      "name = uniform_solidangle\r\n",
      "polar-angle = spin2_polar\r\n",
      "azimuthal-angle = spin2_azimuthal\r\n",
      "\r\n",
      "[prior-distance]\r\n",
      "; following gives a uniform volume prior\r\n",
      "name = uniform_radius\r\n",
      "min-distance = 10\r\n",
      "max-distance = 1000\r\n",
      "\r\n",
      "[prior-coa_phase]\r\n",
      "; coalescence phase prior\r\n",
      "name = uniform_angle\r\n",
      "\r\n",
      "[prior-inclination]\r\n",
      "; inclination prior\r\n",
      "name = sin_angle\r\n",
      "\r\n",
      "[prior-ra+dec]\r\n",
      "; sky position prior\r\n",
      "name = uniform_sky\r\n",
      "\r\n",
      "[prior-polarization]\r\n",
      "; polarization prior\r\n",
      "name = uniform_angle\r\n"
     ]
    }
   ],
   "source": [
    "!cat emcee_pt.ini bbh_precessing.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Write workflow config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('config.ini', 'w') as fout:\n",
    "    fout.write('''\\\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";   Executables\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "[executables]\n",
    "inference = ${which:pycbc_inference}\n",
    "plot = ${which:pycbc_inference_plot_posterior}\n",
    "\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";   Workflow\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "[workflow]\n",
    "accounting-group = ligo.dev.o3.cbc.explore.test\n",
    "log-path = log\n",
    "sampler = emcee_pt.ini\n",
    "inference = bbh_precessing.ini\n",
    "events = GW150914 GW170104\n",
    "sample-rate = 2048\n",
    "data-sample-rate = 4096\n",
    "data-duration = 4096\n",
    "psd-estimation = download ; or data-standard\n",
    "\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";   Inference\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "[inference]\n",
    "verbose =\n",
    "seed = 12\n",
    "config-files = inference.ini data.ini sampler.ini\n",
    "output-file = inference.hdf\n",
    "nprocesses = 10\n",
    "force =\n",
    "\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";   Visualize\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "[plot]\n",
    "input-file = inference.hdf\n",
    "plot-scatter =\n",
    "plot-marginal =\n",
    "plot-prior = inference.ini data.ini\n",
    "\n",
    "[plot-mass1mass2]\n",
    "output-file = plots/posteriors.png\n",
    "parameters = 'mass1 mass2'\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      ";   Executables\r\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      "[executables]\r\n",
      "inference = ${which:pycbc_inference}\r\n",
      "plot = ${which:pycbc_inference_plot_posterior}\r\n",
      "\r\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      ";   Workflow\r\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      "[workflow]\r\n",
      "accounting-group = ligo.dev.o3.cbc.explore.test\r\n",
      "log-path = log\r\n",
      "sampler = emcee_pt.ini\r\n",
      "inference = bbh_precessing.ini\r\n",
      "events = GW150914 GW170104\r\n",
      "sample-rate = 2048\r\n",
      "data-sample-rate = 4096\r\n",
      "data-duration = 4096\r\n",
      "psd-estimation = download ; or data-standard\r\n",
      "\r\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      ";   Inference\r\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      "[inference]\r\n",
      "verbose =\r\n",
      "seed = 12\r\n",
      "config-files = inference.ini data.ini sampler.ini\r\n",
      "output-file = inference.hdf\r\n",
      "nprocesses = 10\r\n",
      "force =\r\n",
      "\r\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      ";   Visualize\r\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\r\n",
      "[plot]\r\n",
      "input-file = inference.hdf\r\n",
      "plot-scatter =\r\n",
      "plot-marginal =\r\n",
      "plot-prior = inference.ini data.ini\r\n",
      "\r\n",
      "[plot-mass1mass2]\r\n",
      "output-file = plots/posteriors.png\r\n",
      "parameters = 'mass1 mass2'\r\n"
     ]
    }
   ],
   "source": [
    "!cat config.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: /home/prayush/src/GWNRTools/bin//gwnrtools_create_public_events_inference_workflow [--options]\r\n",
      "\r\n",
      "Setup workflow to perform Bayesian parameter estimation runs on a custom set\r\n",
      "of public gravitational-wave events using open data\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --version             Prints version information.\r\n",
      "  --verbose             Print logging messages.\r\n",
      "  --output-dir OUTPUT_DIR\r\n",
      "                        Output directory path.\r\n",
      "  --force               If the output-dir already exists, overwrite it.\r\n",
      "                        Otherwise, an OSError is raised.\r\n",
      "  --do-not-fetch-data   Don't fetch GWOSC data.\r\n",
      "  --nprocesses NPROCESSES\r\n",
      "                        Number of processes to use. If not given then only a\r\n",
      "                        single core will be used.\r\n",
      "  --use-mpi             Use MPI to parallelize the sampler\r\n",
      "  --seed SEED           Seed to use for the random number generator that\r\n",
      "                        initially distributes the walkers. Default is 0.\r\n",
      "\r\n",
      "Configuration:\r\n",
      "  Options needed for parsing config file(s).\r\n",
      "\r\n",
      "  --config-files CONFIGFILE [CONFIGFILE ...]\r\n",
      "                        List of config files to be used in analysis.\r\n",
      "  --config-overrides [SECTION:OPTION:VALUE [SECTION:OPTION:VALUE ...]]\r\n",
      "                        List of section,option,value combinations to add into\r\n",
      "                        the configuration file. Normally the gps start and end\r\n",
      "                        times might be provided this way, and user specific\r\n",
      "                        locations (ie. output directories). This can also be\r\n",
      "                        provided as SECTION:OPTION or SECTION:OPTION: both of\r\n",
      "                        which indicate that the corresponding value is left\r\n",
      "                        blank.\r\n",
      "  --config-delete [SECTION:OPTION [SECTION:OPTION ...]]\r\n",
      "                        List of section,option combinations to delete from the\r\n",
      "                        configuration file. This can also be provided as\r\n",
      "                        SECTION which deletes the enture section from the\r\n",
      "                        configuration file or SECTION:OPTION which deletes a\r\n",
      "                        specific option from a given section.\r\n",
      "\r\n",
      "Options for selecting the FFT backend and controlling its performance in this program.:\r\n",
      "  --fft-backends [FFT_BACKENDS [FFT_BACKENDS ...]]\r\n",
      "                        Preference list of the FFT backends. Choices are:\r\n",
      "                        ['fftw', 'numpy']\r\n",
      "  --fftw-measure-level FFTW_MEASURE_LEVEL\r\n",
      "                        Determines the measure level used in planning FFTW\r\n",
      "                        FFTs; allowed values are: [0, 1, 2, 3]\r\n",
      "  --fftw-threads-backend FFTW_THREADS_BACKEND\r\n",
      "                        Give 'openmp', 'pthreads' or 'unthreaded' to specify\r\n",
      "                        which threaded FFTW to use\r\n",
      "  --fftw-input-float-wisdom-file FFTW_INPUT_FLOAT_WISDOM_FILE\r\n",
      "                        Filename from which to read single-precision wisdom\r\n",
      "  --fftw-input-double-wisdom-file FFTW_INPUT_DOUBLE_WISDOM_FILE\r\n",
      "                        Filename from which to read double-precision wisdom\r\n",
      "  --fftw-output-float-wisdom-file FFTW_OUTPUT_FLOAT_WISDOM_FILE\r\n",
      "                        Filename to which to write single-precision wisdom\r\n",
      "  --fftw-output-double-wisdom-file FFTW_OUTPUT_DOUBLE_WISDOM_FILE\r\n",
      "                        Filename to which to write double-precision wisdom\r\n",
      "  --fftw-import-system-wisdom\r\n",
      "                        If given, call fftw[f]_import_system_wisdom()\r\n",
      "\r\n",
      "Options for selecting optimization-specific settings:\r\n",
      "  --cpu-affinity CPU_AFFINITY\r\n",
      "                        A set of CPUs on which to run, specified in a format\r\n",
      "                        suitable to pass to taskset.\r\n",
      "  --cpu-affinity-from-env CPU_AFFINITY_FROM_ENV\r\n",
      "                        The name of an enivornment variable containing a set\r\n",
      "                        of CPUs on which to run, specified in a format\r\n",
      "                        suitable to pass to taskset.\r\n",
      "\r\n",
      "Options for selecting the processing scheme in this program.:\r\n",
      "  --processing-scheme PROCESSING_SCHEME\r\n",
      "                        The choice of processing scheme. Choices are ['mkl',\r\n",
      "                        'numpy', 'cpu', 'cuda']. (optional for CPU scheme) The\r\n",
      "                        number of execution threads can be indicated by\r\n",
      "                        cpu:NUM_THREADS, where NUM_THREADS is an integer. The\r\n",
      "                        default is a single thread. If the scheme is provided\r\n",
      "                        as cpu:env, the number of threads can be provided by\r\n",
      "                        the PYCBC_NUM_THREADS environment variable. If the\r\n",
      "                        environment variable is not set, the number of threads\r\n",
      "                        matches the number of logical cores.\r\n",
      "  --processing-device-id PROCESSING_DEVICE_ID\r\n",
      "                        (optional) ID of GPU to use for accelerated processing\r\n"
     ]
    }
   ],
   "source": [
    "!gwnrtools_create_public_events_inference_workflow -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-17 17:49:18,790 Reading configuration file\n",
      "2020-03-17 17:49:18,792 Using seed 0\n",
      "2020-03-17 17:49:18,794 Running with CPU support: 1 threads\n",
      "2020-03-17 17:49:18,904 Will setup analyses in .\n",
      "2020-03-17 17:49:18,906 Making workspace directories\n",
      "2020-03-17 17:49:18,907 Creating DAG\n",
      "2020-03-17 17:49:18,914 Making eventGW170104/emcee_pt/bbh_precessing in /home/prayush/research/test_pycbc_gw150914\n",
      "2020-03-17 17:49:18,984 Copying config files to eventGW170104/emcee_pt/bbh_precessing\n",
      "2020-03-17 17:49:18,986 Copying executables to eventGW170104/emcee_pt/bbh_precessing/scripts/\n",
      "2020-03-17 17:49:18,988 Fetching GWOSC frame data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.gw-openscience.org/catalog/GWTC-1-confident/data/GW170104/H-H1_GWOSC_4KHZ_R1-1167557889-4096.gwf [Done]\n",
      "Downloading https://www.gw-openscience.org/catalog/GWTC-1-confident/data/GW170104/L-L1_GWOSC_4KHZ_R1-1167557889-4096.gwf [Done]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-17 17:50:43,606 Fetching PSD files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://dcc.ligo.org/public/0158/P1900011/001/GWTC1_GW170104_PSDs.dat [Done]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-17 17:51:37,611 Making eventGW150914/emcee_pt/bbh_precessing in /home/prayush/research/test_pycbc_gw150914\n",
      "2020-03-17 17:51:37,701 Copying config files to eventGW150914/emcee_pt/bbh_precessing\n",
      "2020-03-17 17:51:37,704 Copying executables to eventGW150914/emcee_pt/bbh_precessing/scripts/\n",
      "2020-03-17 17:51:37,706 Fetching GWOSC frame data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.gw-openscience.org/catalog/GWTC-1-confident/data/GW150914/H-H1_GWOSC_4KHZ_R1-1126257415-4096.gwf [Done]\n",
      "Downloading https://www.gw-openscience.org/catalog/GWTC-1-confident/data/GW150914/L-L1_GWOSC_4KHZ_R1-1126257415-4096.gwf [Done]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-17 17:52:54,887 Fetching PSD files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://dcc.ligo.org/public/0158/P1900011/001/GWTC1_GW150914_PSDs.dat [Done]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-17 17:53:50,550 Done\n"
     ]
    }
   ],
   "source": [
    "run -i /home/prayush/src/GWNRTools/bin/gwnrtools_create_public_events_inference_workflow --config-files config.ini --output-dir . --force --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[00m\r\n",
      "├── bbh_precessing.ini\r\n",
      "├── config.ini\r\n",
      "├── emcee_pt.ini\r\n",
      "├── \u001b[01;34meventGW150914\u001b[00m\r\n",
      "│   ├── \u001b[01;34mdata\u001b[00m\r\n",
      "│   │   ├── H-H1_GWOSC_4KHZ_R1-1126257415-4096.gwf\r\n",
      "│   │   ├── L-L1_GWOSC_4KHZ_R1-1126257415-4096.gwf\r\n",
      "│   │   ├── psd_H1.dat\r\n",
      "│   │   └── psd_L1.dat\r\n",
      "│   └── \u001b[01;34memcee_pt\u001b[00m\r\n",
      "│       └── \u001b[01;34mbbh_precessing\u001b[00m\r\n",
      "│           ├── data.ini\r\n",
      "│           ├── inference.hdf.bkup\r\n",
      "│           ├── inference.hdf.checkpoint\r\n",
      "│           ├── inference.ini\r\n",
      "│           ├── \u001b[01;34mlog\u001b[00m\r\n",
      "│           │   ├── run_inference-166-0.err\r\n",
      "│           │   ├── run_inference-166-0.out\r\n",
      "│           │   ├── run_inference-169-0.err\r\n",
      "│           │   ├── run_inference-169-0.out\r\n",
      "│           │   ├── run_inference-173-0.err\r\n",
      "│           │   ├── run_inference-173-0.out\r\n",
      "│           │   └── tmpFgLflx\r\n",
      "│           ├── \u001b[01;32mmake_plot_mass1mass2\u001b[00m\r\n",
      "│           ├── make_plot_mass1mass2.sub\r\n",
      "│           ├── \u001b[01;34mplots\u001b[00m\r\n",
      "│           ├── \u001b[01;32mrun_inference\u001b[00m\r\n",
      "│           ├── run_inference.sub\r\n",
      "│           ├── sampler.ini\r\n",
      "│           └── \u001b[01;34mscripts\u001b[00m\r\n",
      "│               ├── \u001b[01;32mpycbc_inference\u001b[00m\r\n",
      "│               └── \u001b[01;32mpycbc_inference_plot_posterior\u001b[00m\r\n",
      "├── \u001b[01;34meventGW170104\u001b[00m\r\n",
      "│   ├── \u001b[01;34mdata\u001b[00m\r\n",
      "│   │   ├── H-H1_GWOSC_4KHZ_R1-1167557889-4096.gwf\r\n",
      "│   │   ├── L-L1_GWOSC_4KHZ_R1-1167557889-4096.gwf\r\n",
      "│   │   ├── psd_H1.dat\r\n",
      "│   │   └── psd_L1.dat\r\n",
      "│   └── \u001b[01;34memcee_pt\u001b[00m\r\n",
      "│       └── \u001b[01;34mbbh_precessing\u001b[00m\r\n",
      "│           ├── data.ini\r\n",
      "│           ├── inference.ini\r\n",
      "│           ├── \u001b[01;34mlog\u001b[00m\r\n",
      "│           │   ├── run_inference-165-0.err\r\n",
      "│           │   ├── run_inference-165-0.out\r\n",
      "│           │   ├── run_inference-168-0.err\r\n",
      "│           │   ├── run_inference-168-0.out\r\n",
      "│           │   ├── run_inference-172-0.err\r\n",
      "│           │   ├── run_inference-172-0.out\r\n",
      "│           │   └── tmpFgLflx\r\n",
      "│           ├── \u001b[01;32mmake_plot_mass1mass2\u001b[00m\r\n",
      "│           ├── make_plot_mass1mass2.sub\r\n",
      "│           ├── \u001b[01;34mplots\u001b[00m\r\n",
      "│           ├── \u001b[01;32mrun_inference\u001b[00m\r\n",
      "│           ├── run_inference.sub\r\n",
      "│           ├── sampler.ini\r\n",
      "│           └── \u001b[01;34mscripts\u001b[00m\r\n",
      "│               ├── \u001b[01;32mpycbc_inference\u001b[00m\r\n",
      "│               └── \u001b[01;32mpycbc_inference_plot_posterior\u001b[00m\r\n",
      "├── \u001b[01;34mlog\u001b[00m\r\n",
      "├── pycbc_inference_events.dag\r\n",
      "├── pycbc_inference_events.dag.condor.sub\r\n",
      "├── pycbc_inference_events.dag.dagman.log\r\n",
      "├── pycbc_inference_events.dag.dagman.out\r\n",
      "├── pycbc_inference_events.dag.lib.err\r\n",
      "├── pycbc_inference_events.dag.lib.out\r\n",
      "├── pycbc_inference_events.dag.lock\r\n",
      "├── pycbc_inference_events.dag.metrics\r\n",
      "├── pycbc_inference_events.dag.nodes.log\r\n",
      "├── pycbc_inference_events.dag.rescue001\r\n",
      "├── pycbc_inference_events.dag.rescue002\r\n",
      "└── \u001b[01;32mpycbc_inference_events.sh\u001b[00m\r\n",
      "\r\n",
      "15 directories, 57 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit & monitor workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!condor_submit_dag pycbc_inference_events.dag >> dag.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/04/20 14:44:41 Workflow accounting_group_user: <>\r\n",
      "03/04/20 14:44:41 Warning: failed to get attribute DAGNodeName\r\n",
      "03/04/20 14:44:41 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False\r\n",
      "03/04/20 14:44:41 Default node log file is: </home/prayush/research/test_pycbc_gw150914/./pycbc_inference_events.dag.nodes.log>\r\n",
      "03/04/20 14:44:41 DAG Lockfile will be written to pycbc_inference_events.dag.lock\r\n",
      "03/04/20 14:44:41 DAG Input file is pycbc_inference_events.dag\r\n",
      "03/04/20 14:44:41 Parsing 1 dagfiles\r\n",
      "03/04/20 14:44:41 Parsing pycbc_inference_events.dag ...\r\n",
      "03/04/20 14:44:41 Dag contains 4 total jobs\r\n",
      "03/04/20 14:44:41 Sleeping for 3 seconds to ensure ProcessId uniqueness\r\n"
     ]
    }
   ],
   "source": [
    "!tail *dagman.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
